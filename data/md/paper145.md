## **E FFeL: Ensuring Integrity For Federated Learning**



Somesh Jha Laurens van der


Maaten
UW Madison



Amrita Roy
Chowdhury [âˆ—]


UW Madison


**Abstract**



Chuan Guo



Somesh Jha [â€ ]

Meta AI UW Madison



Meta AI



Federated learning (FL) enables clients to collaborate with a server
to train a machine learning model. To ensure privacy, the server
performs secure aggregation of updates from the clients. Unfortunately, this prevents verification of the well-formedness (integrity)
of the updates as the updates are masked. Consequently, malformed
updates designed to poison the model can be injected without detection. In this paper, we formalize the problem of ensuring _both_
update privacy and integrity in FL and present a new system, EIFFeL, that enables secure aggregation of _verified_ updates. EIFFeL is a
general framework that can enforce _arbitrary_ integrity checks and
remove malformed updates from the aggregate, without violating
privacy. Our empirical evaluation demonstrates the practicality of
EIFFeL. For instance, with 100 clients and 10% poisoning, EIFFeL can
train an MNIST classification model to the same accuracy as that
of a non-poisoned federated learner in just 2 _._ 4s per iteration.


**CCS Concepts**


- **Security and privacy** â†’ **Cryptography** ; **Privacy-preserving**
**protocols** .


**Keywords**


Poisoning Attacks, Input Integrity, Secure Aggregation


**ACM Reference Format:**


Amrita Roy Chowdhury, Chuan Guo, Somesh Jha, and Laurens van der
Maaten. 2022. E FFeL: Ensuring Integrity For Federated Learning. In _Pro-_
_ceedings of the 2022 ACM SIGSAC Conference on Computer and Communica-_
_tions Security (CCS â€™22), November 7â€“11, 2022, Los Angeles, CA, USA._ ACM,
[New York, NY, USA, 21 pages. https://doi.org/10.1145/3548606.3560611](https://doi.org/10.1145/3548606.3560611)


**1** **Introduction**


Federated learning (FL; [ 61 ]) is a learning paradigm for decentralized data in which multiple clients collaborate with a server to train
a machine-learning (ML) model. Each client computes an update
on its _local_ training data and shares it with the server; the server
aggregates the local updates into a _global_ model update. This allows


âˆ— Work done during internship at Meta AI

- Employed part-time at Meta during this work


Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
_CCS â€™22, November 7â€“11, 2022, Los Angeles, CA, USA_
Â© 2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9450-5/22/11...$15.00
[https://doi.org/10.1145/3548606.3560611](https://doi.org/10.1145/3548606.3560611)



**Security Goal** **Cryptographic Primitive**


Input Privacy Shamirâ€™s Threshold Secret Sharing Scheme [75]


Secret-Shared Non-Interactive Proof [28]
Input Integrity
Verifiable Secret Shares [35]


**Figure 1: EIFFeL performs secure aggregation of** _**verified**_ **inputs in**
**FL. The table lists its security goals and the cryptographic primi-**
**tives we adopt to achieve them.**


the clients to contribute to model training without sharing their
private data. However, the local updates can still reveal information
about a clientâ€™s private data [ 11, 63, 65, 95, 97 ]. FL addresses this
by using _secure aggregation_ : clients mask the updates they share,
and the server can recover _only_ the final aggregate in the clear.


A major challenge in FL is that it is vulnerable to Byzantine attacks.
In particular, malicious clients can inject poisoned updates into
the learner with the goal of reducing the global model accuracy

[ 10, 12, 34, 45, 62 ] or implanting backdoors in the model that can
be exploited later [ 5, 26, 90 ]. Even a single malformed update can
significantly alter the trained model [ 15 ]. Thus, ensuring the wellformedness of the updates, _i.e._, upholding their _integrity_, is essential
for ensuring robustness in FL. This problem is especially challenging
in the context of secure aggregation as the individual updates are
masked from the server, which prevents audits on them.


These challenges in FL lead to the research question: _How can a_
_federated learner efficiently verify the integrity of clientsâ€™ updates_
_without violating their privacy?_


We formalize this problem by proposing _secure aggregation of veri-_
_fied inputs_ (SAVI) protocols that: ( 1 ) securely verify the integrity
of each local update, ( 2 ) aggregate _only_ well-formed updates, and
( 3 ) release only the final aggregate in the clear. A SAVI protocol allows for checking the well-formedness of updates _without observing_
_them_, thereby ensuring _both_ the privacy and integrity of updates.


We demonstrate the feasibility of SAVI by proposing EIFFeL: a system that instantiates a SAVI protocol that can perform _any integrity_
_check that can be expressed as an arithmetic circuit with public param-_
_eters_ . This provides EIFFeL the flexibility to implement a plethora of
modern ML approaches that ensure robustness to Byzantine attacks
by checking the integrity of per-client updates before aggregating
them [ 5, 31, 54, 76, 83, 84, 92, 93 ]. EIFFeL is a general framework





ğŸ _M_


_u_ 2 = ğ’–



ğ’° = X



.






CCS â€™22, November 7â€“11, 2022, Los Angeles, CA, USA Roy Chowdhury et al.



that empowers a federated learner to deploy (multiple) _arbitrary_
integrity checks of their choosing on the â€œmaskedâ€ updates.


EIFFeL uses secret-shared non-interactive proofs (SNIP; [ 28 ]) which
are a type of zero-knowledge proofs that are optimized for the clientserver setting. SNIP, however, requires multiple honest verifiers to
check the proof. EIFFeL extends SNIP to a _malicious_ threat model
by carefully _co-designing its architectural and cryptographic compo-_
_nents_ . Moreover, we develop a suite of optimizations that improve
EIFFeLâ€™s performance by at least 2 _._ 3 Ã— . Our empirical evaluation
of EIFFeL demonstrates its practicality for real-world usage. For
instance, with 100 clients and a poisoning rate of 10%, EIFFeL can
train an MNIST classification model to the same accuracy as that
of a non-poisoned federated learner in just 2 _._ 4 _ğ‘ _ per iteration.


**2** **Problem Overview**


In this section, we introduce the problem setting, followed by its
threat analysis and an overview of our solution.


**2.1** **Problem Setting**


In FL, multiple parties with distributed data jointly train a _global_
_model_, M, without explicitly disclosing their data to each other. FL
has two types of actors:

- **Clients.** There are _ğ‘›_ clients where each client, C _ğ‘–_ _,ğ‘–_ âˆˆ[ _ğ‘›_ ], owns
a private dataset, _ğ·_ _ğ‘–_ . The raw data is never shared, instead, every client computes a local update for M, such as the average
gradient, over the private dataset _ğ·_ _ğ‘–_ .

- **Server.** There is a single _untrusted_ server, S, who coordinates
the updates from different clients to train M.
A single training iteration in FL consists of the following steps:

- **Broadcast.** The server broadcasts the current parameters of the
model M to all the clients.

- **Local computation.** Each client C _ğ‘–_ locally computes an update,
_ğ‘¢_ _ğ‘–_, on its dataset _ğ·_ _ğ‘–_ .

- **Aggregation.** The server S collects the client updates and aggregates them, U = [ï¿½] _ğ‘–_ âˆˆ[ _ğ‘›_ ] _[ğ‘¢]_ _ğ‘–_ [.]

- **Global model update.** The server S updates the global model
M based on the aggregated update U.
In settings where there is a large number of clients, it is typical to
subsample a small subset of clients to participate in a given iteration.
We assume _ğ‘›_ to denote the number of clients that participate in
each iteration and C denotes the subset of these _ğ‘›_ clients, which
the server announces at the beginning of the iteration.

**2.2** **Security Goals**


- **Input Privacy (Clientâ€™s Goal).** The first goal is to ensure privacy for all _honest_ clients. That is, no party should be able learn
anything about the raw input (update) _ğ‘¢_ _ğ‘–_ of an honest client _ğ¶_ _ğ‘–_,
other than what can be learned from the final aggregate U .

- **Input Integrity (Serverâ€™s Goal).** The server S is motivated to
ensure that the individual updates from each client are wellformed. Specifically, the server has a _public_ validation predicate,
Valid(Â·), that defines a syntax for the inputs (updates). An input
(update) _ğ‘¢_ is considered valid and, hence, passes the integrity
check iff Valid( _ğ‘¢_ ) = 1 . For instance, any per-client update check,
such as Zeno++ [ 93 ], can be a good candidate for Valid(Â·) (we
evaluate four state-of-the-art validation predicates in Sec. 7.2).



We assume that the honest clients, denoted by C _ğ»_ : ( 1 ) follow the
protocol correctly, _and_ ( 2 ) have well-formed inputs. We require the
second condition because, in case the input of an honest client does
not pass the integrity check (which can be verified locally since
Valid(Â·) is public), the client has no incentive to participate in the
training iteration.


**2.3** **Threat Model**


We consider a _malicious adversary_ threat model:

- **Malicious Server.** We consider a malicious server that can de
viate from the protocol arbitrarily with the aim of recovering the
raw updates _ğ‘¢_ _ğ‘–_ for _ğ‘–_ âˆˆ[ _ğ‘›_ ] (see Remark 1 later for more details).

- **Malicious Clients.** We also consider a set of _ğ‘š_ malicious clients,
C _ğ‘€_ . Malicious clients can arbitrarily deviate from the protocol
with the goals of: (1) sending malformed inputs to the server and
thus, compromising the final aggregate; (2) failing the integrity
check of an honest client that submits well-formed updates; (3)
violating the privacy of an honest client, potentially in collusion
with the server.


**2.4** **Solution Overview**


Prior work has mostly focused on ensuring input privacy via secure
aggregation, _i.e._, securely computing the aggregate U = [ï¿½] C _ğ‘–_ âˆˆC _[ğ‘¢]_ _ğ‘–_ [.]
Motivated by the above problem setting and threat analysis, we
introduce a new type of FL protocol, called _secure aggregation with_
_verified inputs_ (SAVI), that ensures _both_ input privacy and integrity.
The goal of a SAVI protocol is to securely aggregate _only_ wellinformed inputs.
In order to demonstrate the feasibility of SAVI, we propose EIFFeL:
a system that instantiates a SAVI protocol for any Valid(Â·) that can
be expressed as an arithmetic circuit with public parameters (Fig.
1). EIFFeL ensures input privacy by using Shamirâ€™s threshold secret
sharing scheme [ 75 ] (Sec. 4.1). Input integrity is guaranteed via SNIP
and verifiable secret shares (VSS) which validates the correctness
of the secret shares (Sec. 4.1). The key ideas are:

- SNIP requires multiple honest verifiers. EIFFeL enables this in
a single-server setting by having the clients act as the verifiers
for each other under the supervision of the server (in Fig. 2b,
verifiers are marked by ).

- EIFFeL extends SNIP to the malicious threat model to account

for the malicious clients (verifiers). Our key observation is that
using a threshold secret sharing scheme creates multiple subsets
of clients that can emulate the SNIP verification protocol. The
server uses this redundancy to robustly verify the proofs and
aggregate updates with verified proofs _only_ (Fig. 2c and 2d).


**3** **Secure Aggregation with Verified Inputs**


Below, we provide the formal definition of a _secure aggregation with_
_verified inputs_ (SAVI) protocol.


Definition 1. _Given a public validation predicate_ _Valid_ (Â·) _and se-_
_curity parameter_ _ğœ…_ _, a protocol_ Î ( _ğ‘¢_ 1 _,_ - Â· Â· _,ğ‘¢_ _ğ‘›_ ) _is a secure aggregation_
_with verified inputs (SAVI) protocol if:_


- _**Integrity.**_ _The output of the protocol,_ _out_ _, returns the aggregate_
_of a subset of clients,_ C _Valid_ _, such that all clients in_ C _Valid_ _have_
_well-formed inputs._


E FFeL: Ensuring Integrity For Federated Learning CCS â€™22, November 7â€“11, 2022, Los Angeles, CA, USA



**(a) EIFFeL consists of multiple clients**
C **and a server** S **with a public vali-**
**dation predicate Valid** (Â·) **that defines**
**the integrity check. A client** C _ğ‘–_ **needs**
**to provide a proof** _ğœ‹_ _ğ‘–_ **for Valid** ( _ğ‘¢_ _ğ‘–_ ) = 1
**(Round 1).**



**(b) For checking the proof** _ğœ‹_ _ğ‘–_ **, all**
**other clients** C \ _ğ‘–_ **act as the verifiers**
**under the supervision of** S **.** _ğ¶_ _ğ‘–_ **splits**
**its update** _ğ‘¢_ _ğ‘–_ **and proof** _ğœ‹_ _ğ‘–_ **using**
**Shamirâ€™s scheme with threshold** _ğ‘š_ +1
**and shares it with** C \ _ğ‘–_ **(Round 2).**



**(c) Conceptually, any set of** _ğ‘š_ + 1
**clients in** C \ _ğ‘–_ **can emulate the SNIP**
**verification protocol. The server uses**
**this redundancy to** _**robustly**_ **verify**
**the proof (Round 3).**



**(d) The clients only aggregate the**
**shares of well-formed updates and**
**the resulting aggregate is revealed to**
**the server (Round 4).**



**Figure 2: High-level overview of EIFFeL. See Sec. 2.4 for key ideas, and Sec. 4.4 for a detailed description of the system.**



Prï¿½ _out_ = U _Valid_ ï¿½ â‰¥ 1 âˆ’ negl( _ğœ…_ ) _where_ U _Valid_ = âˆ‘ï¸ _ğ‘¢_ _ğ‘–_

C _ğ‘–_ âˆˆC _Valid_


_for all_ C _ğ‘–_ âˆˆC _Valid_ _we have Valid_ ( _ğ‘¢_ _ğ‘–_ ) = 1


C _ğ»_ âŠ†C _Valid_ âŠ†C _._ (1)


- _**Privacy.**_ _For a set of malicious clients_ C _ğ‘€_ _and a malicious server_

S _, there exists a probabilistic polynomial-time (P.P.T.) simulator_
Sim(Â·) _such that:_


Real Î  ï¿½{ _ğ‘¢_ C _ğ»_ } _,_ Î© C _ğ‘€_ âˆªS ï¿½ â‰¡ _ğ¶_ Simï¿½U _ğ»_ _,_ C _ğ»_ _,_ Î© C _ğ‘€_ âˆªS ï¿½

_where_ U _ğ»_ = âˆ‘ï¸ _ğ‘¢_ _ğ‘–_ _._ (2)

C _ğ‘–_ âˆˆC _ğ»_


{ _ğ‘¢_ C _ğ»_ } _denotes the input of all the honest clients,_ Real Î  _denotes_
_a random variable representing the joint view of all the parties_
_in_ Î  _â€™s execution,_ Î© C _ğ‘€_ âˆªS _indicates a polynomial-time algorithm_
_implementing the â€œnext-messageâ€ function of the parties in_ C _ğ‘€_ âˆªS
_(see App. 11.5), and_ â‰¡ _ğ¶_ _denotes computational indistinguishability._


From Def. 1, the output of a SAVI protocol is of the form:







U _ğ‘£ğ‘ğ‘™ğ‘–ğ‘‘_ = U _ğ»_

ï¿½ï¿½ï¿½ï¿½


well-formed updates of
_all_ honest clients C _ğ»_



+ _ğ‘¢_ _ğ‘–_ _._
âˆ‘ï¸

C _ğ‘–_ âˆˆC Valid \C _ğ»_


ï¿½ **ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½** ï¿½ï¿½ **ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½** ï¿½


well-formed updates of
some malicious clients



(3)



The clients in C Valid \ C _ğ»_ are clients who have submitted wellformed inputs but can behave maliciously otherwise ( _e.g._, by violating input privacy/integrity of honest clients).


The privacy constraint of the SAVI protocol means that a simulator
Sim can generate the views of all parties with just access to the
list of the honest clients C _ğ»_ and their aggregate U _ğ»_ . Note that
Sim takes U _ğ»_ as an input instead of the protocol output U Valid .
This is because the clients in C Valid \ C _ğ»_, by virtue of being malicious, can behave arbitrarily and announce their updates to reveal
U _ğ»_ = U Valid âˆ’ [ï¿½] C _ğ‘–_ âˆˆC Valid \C _ğ»_ _[ğ‘¢]_ _ğ‘–_ [. Thus,][ SAVI][ ensures that nothing can]
be learned about the input _ğ‘¢_ _ğ‘–_ of an honest client C _ğ‘–_ âˆˆC _ğ»_ except:


- that _ğ‘¢_ _ğ‘–_ is well-formed, _i.e._, Valid( _ğ‘¢_ _ğ‘–_ ) = 1,

- anything that can be learned from the aggregate U _ğ»_ .



**4** **EIFFeL System Description**


This section introduces EIFFeL: the system we propose to perform
secure aggregation of verified inputs.


**4.1** **Cryptographic Building Blocks**


**Arithmetic Circuit.** An arithmetic circuit, C : F _[ğ‘˜]_ â†¦â†’ F, represents
a computation over a finite field F . Conceptually, it is similar to a
Boolean circuit but it uses finite field addition, multiplication and
multiplication-by-constant instead of OR, AND, and NOT gates.


CCS â€™22, November 7â€“11, 2022, Los Angeles, CA, USA Roy Chowdhury et al.



**Shamirâ€™s** _ğ‘¡_ **-out-of-** _ğ‘›_ **Secret Sharing Scheme [75]** allows distributing a secret _ğ‘ _ among _ğ‘›_ parties such that: (1) the complete secret can
be reconstructed from any combination of _ğ‘¡_ shares; (2) any set of
_ğ‘¡_ âˆ’ 1 or fewer shares reveals no information about _ğ‘ _ where _ğ‘¡_ is the

_threshold_ of the secret sharing scheme. The scheme is parameterized
over a finite field F and consists of two algorithms:


$

- {( _ğ‘–,ğ‘ _ _ğ‘–_ )} _ğ‘–_ âˆˆ _ğ‘ƒ_ â†âˆ’ SS.share( _ğ‘ , ğ‘ƒ,ğ‘¡_ ) . Given a secret _ğ‘ _ âˆˆ F, a set of _ğ‘›_
unique field elements _ğ‘ƒ_ âˆˆ F _[ğ‘›]_ and a threshold _ğ‘¡_ with _ğ‘¡_ â‰¤ _ğ‘›_, this
algorithm constructs _ğ‘›_ shares. The algorithm chooses a random
polynomial _ğ‘_ âˆˆ F[ _ğ‘‹_ ] such that _ğ‘_ (0) = _ğ‘ _ and generates the shares
as ( _ğ‘–, ğ‘_ ( _ğ‘–_ )) _,ğ‘–_ âˆˆ _ğ‘ƒ_ .

- _ğ‘ _ â† SS.recon({( _ğ‘–,ğ‘ _ _ğ‘–_ ) _ğ‘–_ âˆˆ _ğ‘„_ }) . Given the shares corresponding to a
subset _ğ‘„_ âŠ† _ğ‘ƒ,_ | _ğ‘„_ | â‰¥ _ğ‘¡_, the reconstruction algorithm recovers the

secret _ğ‘ _ .


Shamirâ€™s secret sharing scheme is _linear_, which means a party
can _locally_ perform: ( 1 ) addition of two shares, ( 2 ) addition of a
constant, and (3) multiplication by a constant.
Shamirâ€™s secret sharing scheme is closely related to Reed-Solomon
error correcting codes [ 55 ], which is a group of polynomial-based
error correcting codes. The share generation is similar to (nonsystemic) message encoding in these codes which can successfully
recover a message even in the presence of errors and erasures
(message dropouts). Consequently, we can leverage Reed-Solomon
decoding for robust reconstruction of Shamirâ€™s secret shares:

- _ğ‘ _ â† SS.robustRecon({( _ğ‘–,ğ‘ _ _ğ‘–_ )} _ğ‘–_ âˆˆ _ğ‘„_ ) . Shamirâ€™s secret sharing scheme
results in a [ _ğ‘›,ğ‘¡,ğ‘›_ âˆ’ _ğ‘¡_ + 1] Reed-Solomon code that can tolerate up to _ğ‘_ errors and _ğ‘’_ erasures (message dropouts) such that
2 _ğ‘_ + _ğ‘’_ _< ğ‘›_ âˆ’ _ğ‘¡_ + 1 . Given any subset of _ğ‘›_ âˆ’ _ğ‘’_ shares _ğ‘„_ âŠ† _ğ‘ƒ,_ | _ğ‘„_ | â‰¥ _ğ‘›_ âˆ’ _ğ‘’_
with up to _ğ‘_ errors, any standard Reed Solomon decoding algorithm [ 13 ] can robustly reconstruct _ğ‘ _ . EIFFeL uses Gaoâ€™s decoding
algorithm [37].


_Verifiable secret sharing scheme_ is a related concept where the
scheme has an additional property of _verifiability_ . Given a share
of the secret, a party must be able to check whether it is indeed
a valid share. If a share is valid, then there exists a unique secret
which will be the output of the reconstruction algorithm when run
on any _ğ‘¡_ distinct valid shares. Formally:


- 1/0 â† SS.verify(( _ğ‘–, ğ‘£_ ) _,_ Î¨)) . The verification algorithm inputs a share
and a check string Î¨ _ğ‘ _ such that


âˆ€ _ğ‘‰_ âŠ‚ F Ã— F where | _ğ‘‰_ | = _ğ‘¡,_ âˆƒ _ğ‘ _ âˆˆ F s.t.


(âˆ€( _ğ‘–, ğ‘£_ ) âˆˆ _ğ‘‰,_ SS.verify (( _ğ‘–, ğ‘£_ ) _,_ Î¨ _ğ‘ _ ) = 1) =â‡’ SS.recon ( _ğ‘‰_ ) = _ğ‘ _


The share construction algorithm is augmented to output the
check string as ({( _ğ‘–,ğ‘ _ _ğ‘–_ ) _ğ‘–_ âˆˆ _ğ‘ƒ_ } _,_ Î¨ _ğ‘ _ ) â† SS.share( _ğ‘ , ğ‘ƒ,ğ‘¡_ ) .

For EIFFeL, we use the non-interactive verification scheme by Feldman [35] (details in App. 11.1).


**Key Agreement Protocol.** A key agreement protocol consists of
a tuple of the following three algorithms:


- ( _ğ‘ğ‘_ ) â†âˆ’ $ KA.param(1 _ğœ…_ ) . The parameter generation algorithm samples a set of public parameters _ğ‘ğ‘_ with security parameter _ğœ…_ .

$

- ( _ğ‘ğ‘˜,ğ‘ ğ‘˜_ ) â†âˆ’ KA.gen( _ğ‘ğ‘_ ) . The key generation algorithm samples a
public/secret key pair from the public parameters.



Sim _ğœ‹_ ( Valid (Â·) _,_ {([ _ğ‘¥_ ] _ğ‘–_ _,_ [ _ğœ‹_ ] _ğ‘–_ )} _ğ‘–_ âˆˆVÂ¯ [) â‰¡] [View] _ğœ‹,_ V [Â¯] [(] [Valid] [(Â·)] _[,ğ‘¥]_ [)] _[.]_


Thus, SNIP allows the verifiers to collaboratively check â€“ without ever accessing the proverâ€™s private data in the clear â€“ that the




- _ğ‘ ğ‘˜_ _ğ‘–ğ‘—_ â† KA.agree( _ğ‘ğ‘˜_ _ğ‘–_ _,ğ‘ ğ‘˜_ _ğ‘—_ ) . The key agreement protocol receives a
public key _ğ‘ğ‘˜_ _ğ‘–_ and a secret key _ğ‘ ğ‘˜_ _ğ‘—_ as input and generates the
shared key _ğ‘ ğ‘˜_ _ğ‘–ğ‘—_ .


**Authenticated Encryption** provides confidentiality and integrity
guarantees for messages exchanged between two parties. It consists
of a tuple of three algorithms as follows:

- _ğ‘˜_ â†âˆ’ $ AE.gen(1 _ğœ…_ ) . The key generation algorithm that outputs a
private key _ğ‘˜_ where _ğœ…_ is the security parameter.

$

- ~~_ğ‘¥_~~ â†âˆ’ AE.enc( _ğ‘˜,ğ‘¥_ ) . The encryption algorithm takes as input a key
_ğ‘˜_ and a message _ğ‘¥_, and outputs a ciphertext ~~_ğ‘¥_~~ .

- _ğ‘¥_ â† AE.dec( _ğ‘˜,_ ~~_ğ‘¥_~~ ~~)~~ . The decryption algorithm takes as input a ciphertext and a key and outputs either the original plaintext, or a
special error symbol âŠ¥ on failure.

**Secret-shared Non-interactive Proofs.** The secret-shared non
interactive proof (SNIP) [ 28 ] is an information-theoretic zero-knowledge proof for distributed data (Fig. 3). SNIP is designed for a multiverifier setting where the private data is distributed or secret-shared
among the verifiers. Specifically, SNIP relies on an additive secret
sharing scheme over a field F as described below. A secret _ğ‘ _ âˆˆ F is
split into _ğ‘˜_ random shares ([ _ğ‘ _ ] 1 _,_ - Â· Â· _,_ [ _ğ‘ _ ] _ğ‘˜_ ) such that [ï¿½] _[ğ‘˜]_ _ğ‘–_ =1 [[] _[ğ‘ ]_ []] _[ğ‘–]_ [=] _[ ğ‘ ]_ [.]
A subset of up to _ğ‘˜_ âˆ’ 1 shares reveals _no_ information about the
secret _ğ‘ _ . The additive secret-sharing scheme is linear as well.


_SNIP Setting._ SNIP considers _ğ‘˜_ â‰¥ 2 verifiers {V _ğ‘–_ } _,ğ‘–_ âˆˆ[ _ğ‘˜_ ] and a prover
P with a private vector _ğ‘¥_ âˆˆ F _[ğ‘‘]_ . All parties also hold a _public_ arithmetic circuit representing a validation predicate Valid : F _[ğ‘‘]_ â†¦â†’ F . Let
M be the number of multiplication gates in Valid(Â·) . F is chosen such
that 2M â‰ª|F| . The prover P splits _ğ‘¥_ into _ğ‘˜_ shares {[ _ğ‘¥_ 1 ] _,_ - Â· Â· _,_ [ _ğ‘¥_ _ğ‘˜_ ]} .
Next, they generate _ğ‘˜_ proof strings [ _ğœ‹_ ] _ğ‘–_ _,ğ‘–_ âˆˆ[ _ğ‘˜_ ] based on Valid(Â·)
and shares ([ _ğ‘¥_ _ğ‘–_ ] _,_ [ _ğœ‹_ ] _ğ‘–_ ) with every verifier V _ğ‘–_ (Fig. 3a).
The proverâ€™s goal is to convince the verifiers that, indeed, Valid( _ğ‘¥_ ) = 1 .
The prover does so via proof strings [ _ğœ‹_ ] _ğ‘–_ _,ğ‘–_ âˆˆ[ _ğ‘˜_ ], that do not reveal
anything else about _ğ‘¥_ . After receiving the proof, the verifiers gossip
with each other to conclude either that Valid( _ğ‘¥_ ) = 1 (the verifiers

â€œ
Accept _ğ‘¥_ ") or not (â€œ Reject _ğ‘¥_ â€, Figs. 3b and 3c). Formally, SNIP satisfies
the following security properties:


- _Completeness._ If all parties are honest and Valid( _ğ‘¥_ ) = 1, then the
verifiers will accept _ğ‘¥_ .


âˆ€ _ğ‘¥_ âˆˆ F s.t. Valid ( _ğ‘¥_ ) = 1 : Pr _ğœ‹_ [ Accept _ğ‘¥_ ] = 1 _._


- _Soundness_ . If all verifiers are honest, and if Valid( _ğ‘¥_ ) = 0, then for all
malicious provers, the verifiers will reject _ğ‘¥_ with overwhelming
probability.


âˆ€ _ğ‘¥_ âˆˆ F s.t. Valid ( _ğ‘¥_ ) = 0 : Pr _ğœ‹_ ï¿½Reject _ğ‘¥_ ï¿½ â‰¥ 1 âˆ’ (2 _ğ‘€_ âˆ’2) / |F | _._


- _Zero knowledge._ If the prover and at least one verifier are honest,
then the verifiers learn nothing about _ğ‘¥_, except that Valid( _ğ‘¥_ ) = 1 .
Formally, when Valid( _ğ‘¥_ ) = 1, there exists a simulator Sim(Â·) that
can simulate the view of the protocol execution for every proper
subset of verifiers:



âˆ€ _ğ‘¥_ s.t. Valid ( _ğ‘¥_ ) = 1 and âˆ€V âŠ‚ [Â¯]



_ğ‘˜_
ï¿½



V _ğ‘–_ we have

_ğ‘–_ =1


E FFeL: Ensuring Integrity For Federated Learning CCS â€™22, November 7â€“11, 2022, Los Angeles, CA, USA



**(a) Prover sends secret shares of its input and**
**the SNIP proof to multiple verifiers.**



**(b) The verifiers gossip among themselves** **(c) The check passes successfully if all veri-**
**and check the proof.** **fiers are honest.**

**Figure 3: High-level overview of a secret-shared non-interactive proof (SNIP; [28]).**



**(b) The verifiers gossip among themselves**
**and check the proof.**



proverâ€™s submission is, indeed, well-formed. SNIP works in two
stages as follows:
( 1 ) _Generation of Proof._ For generating the proof, the prover P first
evaluates the circuit Valid(Â·) on its input _ğ‘¥_ to obtain the value of every wire in the arithmetic circuit corresponding to the computation
of Valid( _ğ‘¥_ ) . Using these wire values, P constructs three polynomials _ğ‘“_, _ğ‘”_, and _â„_ of the lowest possible degrees such that _â„_ = _ğ‘“_ - _ğ‘”_ and
_ğ‘“_ ( _ğ‘—_ ) _,ğ‘”_ ( _ğ‘—_ ) and _â„_ ( _ğ‘—_ ) _, ğ‘—_ âˆˆ ï¿½Mï¿½ encode the values of the two input wires
and one output wire of the _ğ‘—_ -th multiplication gate, respectively.
P also samples a single set of Beaverâ€™s multiplication triples [ 7 ]:
( _ğ‘,ğ‘,ğ‘_ ) âˆˆ F [3] such that _ğ‘_ - _ğ‘_ = _ğ‘_ âˆˆ F . Finally, it generates the shares of
the proof, [ _ğœ‹_ ] _ğ‘–_ = [ï¿½] [ _â„_ ] _ğ‘–_ _,_ ([ _ğ‘_ ] _ğ‘–_ _,_ [ _ğ‘_ ] _ğ‘–_ _,_ [ _ğ‘_ ] _ğ‘–_ ) [ï¿½], which consists of:

- shares of the coefficients of the polynomial _â„_, denoted by [ _â„_ ] _ğ‘–_,

- shares of the Beaverâ€™s triples, ([ _ğ‘_ ] _ğ‘–_ _,_ [ _ğ‘_ ] _ğ‘–_ _,_ [ _ğ‘_ ] _ğ‘–_ ) âˆˆ F [3] .


The prover then sends the respective shares of the input and the
proof ([ _ğ‘¥_ ] _ğ‘–_ _,_ [ _ğœ‹_ ] _ğ‘–_ ) to each of the verifiers V _ğ‘–_ .


( 2 ) _Verification of Proof_ . To verify that Valid( _ğ‘¥_ ) = 1 and hence, accept
the input _ğ‘¥_, the verifiers need to check two things:

- check that the value of final output wire of the computation,

Valid( _ğ‘¥_ ), denoted by _ğ‘¤_ _[ğ‘œğ‘¢ğ‘¡]_ is indeed 1, and

- check the consistency of Pâ€™s computation of Valid( _ğ‘¥_ ) .
To this end, each verifier V _ğ‘–_ _locally_ constructs the shares of every
wire in Valid( _ğ‘¥_ ) via affine operations on the shares of the private input [ _ğ‘¥_ ] _ğ‘–_ and [ _â„_ ] _ğ‘–_ . Next, V _ğ‘–_ broadcasts a summary [ _ğœ_ ] _ğ‘–_ = ([ _ğ‘¤_ _[ğ‘œğ‘¢ğ‘¡]_ ] _ğ‘–_ _,_ [ _ğœ†_ ] _ğ‘–_ ),
where [ _ğ‘¤_ _[ğ‘œğ‘¢ğ‘¡]_ ] _ğ‘–_ is V _ğ‘–_ â€™s share of the output wire of the circuit and

[ _ğœ†_ ] _ğ‘–_ is a share of a random digest that the verifier computes from
the shares of the other wire values and the proof string [ _ğœ‹_ ] _ğ‘–_ . Using
these summaries, the verifiers check the proof as follows:

- For checking the output wire, the verifiers can reconstruct its
exact value from all the broadcasted shares _ğ‘¤_ _[ğ‘œğ‘¢ğ‘¡]_ = [ï¿½] _[ğ‘˜]_ _ğ‘–_ =1 [[] _[ğ‘¤]_ _[ğ‘œğ‘¢ğ‘¡]_ []] _[ğ‘–]_
and check whether _ğ‘¤_ _[ğ‘œğ‘¢ğ‘¡]_ = 1 . This would imply that Valid( _ğ‘¥_ ) = 1 .

- The circuit consistency check is more involved and is performed
using the random digest _ğœ†_ . First, V _ğ‘–_ _locally_ computes the shares
of the polynomials _ğ‘“_ and _ğ‘”_ (denoted as [ _ğ‘“_ ] _ğ‘–_ and [ _ğ‘”_ ] _ğ‘–_ ). To verify
the consistency of the circuit evaluation, the verifiers need to
check that the shares [ _â„_ ] _ğ‘–_ sent by the prover P are of the correct
polynomial, _i.e._, confirm that _ğ‘“_  - _ğ‘”_ = _â„_ . For this, SNIP uses the
Schwartz-Zippel polynomial identity test [ 74, 98 ]. Specifically,
verifiers reconstruct _ğœ†_ = [ï¿½] _[ğ‘˜]_ 1=1 [[] _[ğœ†]_ []] _[ğ‘–]_ [from the broadcasted shares]
and test whether _ğœ†_ = _ğ‘Ÿ_ ( _ğ‘“_ ( _ğ‘Ÿ_ ) Â· _ğ‘”_ ( _ğ‘Ÿ_ ) âˆ’ _â„_ ( _ğ‘Ÿ_ )) = 0 on a randomly selected _ğ‘Ÿ_ âˆˆ F . The computation of the share of the random digest

[ _ğœ†_ ] _ğ‘–_ uses the shares of Beaverâ€™s triples ([ _ğ‘_ ] _ğ‘–_ _,_ [ _ğ‘_ ] _ğ‘–_ _,_ [ _ğ‘_ ] _ğ‘–_ ) .
A more detailed description of the SNIP protocol is in App. 11.1.

**4.2** **System Building Blocks**
**Public Validation Predicate.** EIFFeL requires a public validation
predicate Valid(Â·), expressed by an arithmetic circuit, that captures



the notion of update well-formedness. In principle, any per-client
update robustness test [ 5, 31, 54, 76, 83, 84, 93 ] from the ML literature can be a suitable candidate. The parameters of the test (for
instance, threshold _ğœŒ_ for a norm bound check Valid( _ğ‘¢_ ) = I[âˆ¥ _ğ‘¢_ âˆ¥ 2 _< ğœŒ_ )
can be computed from a clean, public dataset D _ğ‘ƒ_ that is available to
the server S . This assumption of a clean, public dataset is common
in both ML [ 24, 45, 93 ] as well as privacy literature [ 6, 8, 57 ]. The
dataset can be small and obtained by manual labeling [60].
**Public Bulletin Board.** EIFFeL assumes the availability of a public
bulletin board B that is accessible to all the parties, similar to prior
work [ 17, 45, 72 ]. In practice, the bulletin B can be implemented as
an append-only log hosted at a public web address where every message and its sender is visible. Every party in EIFFeL has read/write
access to it. We use the bulletin B as a tool for broadcasting [ 21, 30 ].


**4.3** **EIFFeL Design Goals**


In terms of the design, EIFFeL should:


- provide _flexibility in the choice of integrity checks._

- be _compatible with the existing FL infrastructure in deployment._

- be _efficient_ in performance.


**4.4** **EIFFeL Workflow**


The goal of EIFFeL is to instantiate a secure aggregation with verified inputs (SAVI) protocol in FL. For a given public validation
predicate Valid(Â·), EIFFeL checks the integrity of every client update using SNIP and outputs the aggregate of _only_ well-formed
updates, _i.e._, Valid( _ğ‘¢_ ) = 1 . To implement SNIP for our setting, EIFFeL introduces two main ideas:


CCS â€™22, November 7â€“11, 2022, Los Angeles, CA, USA Roy Chowdhury et al.



The full protocol is presented in Fig. 4. The protocol involves a
setup phase followed by four rounds.


**Setup Phase.** In the setup phase, all parties are initialized with the
system-wide parameters, namely the security parameter _ğœ…_, the number of clients _ğ‘›_ out of which _only_ _ğ‘š_ _<_ âŒŠ _[ğ‘›]_ [âˆ’] ~~3~~ [1] [âŒ‹] [can be malicious, public]

$
parameters for the key agreement protocol _ğ‘ğ‘_ â†âˆ’ KA.param( _ğœ…_ ), and
a field F where |F| â‰¥ 2 _[ğœ…]_ . EIFFeL works in a synchronous protocol between the server S and the _ğ‘›_ clients in four rounds. To prevent the
server from simulating an arbitrary number of clients, the clients
register themselves with a specific user ID on the public bulletin
board B and are authenticated with the help of standard public
key infrastructure (PKI). The bulletin board B allows parties to
register IDs only for themselves, preventing impersonation. More
concretely, the PKI enables the clients to register identities (public
keys), and sign messages using their identity (associated secret
keys), such that others can verify this signature, but cannot impersonate them [ 46 ]. We omit this detail for the ease of exposition.
For notational simplicity, we assume that each client C _ğ‘–_ is assigned
a unique logical ID in the form of an integer _ğ‘–_ in [ _ğ‘›_ ] . Each client
holds as input a _ğ‘‘_ -dimensional vector _ğ‘¢_ _ğ‘–_ âˆˆ F _[ğ‘‘]_ representing its local
update. All clients have a private, authenticated communication
channel with the server S . Additionally, every party (clients and
server) has read and write access to the public bulletin B via authenticated channels. For every client C _ğ‘–_, the server S maintains
a list, Flag[ _ğ‘–_ ], of all clients that have flagged C _ğ‘–_ as malicious. All
Flag[ _ğ‘–_ ] lists are initialized to be empty lists.


**Round 1 (Announcing Public Information).** In the first round,
all the parties announce their public information relevant to the protocol on the public bulletin B . Specifically, each client C _ğ‘–_ generates

$
its key pair ( _ğ‘ğ‘˜_ _ğ‘–_ _,ğ‘ ğ‘˜_ _ğ‘–_ ) â†âˆ’ KA.gen( _ğ‘ğ‘_ ) and advertises the public key
_ğ‘ğ‘˜_ _ğ‘–_ on the public bulletin B . The server S publishes the validation
predicate Valid(Â·) on B.


**Round 2 (Generate and Distribute Proofs).** Every client generates shares of its private update _ğ‘¢_ _ğ‘–_ and the proof _ğœ‹_ _ğ‘–_, and distributes these shares to the other clients C \ _ğ‘–_ . First, client C _ğ‘–_ generates a common pairwise encryption key _ğ‘ ğ‘˜_ _ğ‘–ğ‘—_ for every other client
C _ğ‘—_ âˆˆC \ _ğ‘–_ using the key agreement protocol, _ğ‘ ğ‘˜_ _ğ‘–ğ‘—_ â† KA.agree( _ğ‘ ğ‘˜_ _ğ‘–_ _, ğ‘ğ‘˜_ _ğ‘—_ ) .
Next, the client generates the secret shares of its private update

$
{(1 _,ğ‘¢_ _ğ‘–_ 1 ) _,_ - Â· Â· _,_ ( _ğ‘›,ğ‘¢_ _ğ‘–ğ‘›_ ) _,_ Î¨ _ğ‘¢_ _ğ‘–_ } â†âˆ’ SS.share( _ğ‘¢,_ [ _ğ‘›_ ] _,ğ‘š_ + 1) . The sharing of _ğ‘¢_ _ğ‘–_
is performed dimension-wise; we abuse notations and denote the
_ğ‘—_ -th such share by ( _ğ‘—,ğ‘¢_ _ğ‘–ğ‘—_ ) _, ğ‘—_ âˆˆ[ _ğ‘›_ ] . Note that the client C _ğ‘–_ generates
a share ( _ğ‘–,ğ‘¢_ _ğ‘–ğ‘–_ ) for _itself_ as well which will be used later in the
protocol. Next, the client C _ğ‘–_ generates the proof for the computation Valid( _ğ‘¢_ _ğ‘–_ ) = 1 . Specifically, it computes the polynomials _ğ‘“_ _ğ‘–_ _,ğ‘”_ _ğ‘–_,
and _â„_ _ğ‘–_ = _ğ‘“_ _ğ‘–_ - _ğ‘”_ _ğ‘–_ and samples a set of Beaverâ€™s multiplication triples
( _ğ‘_ _ğ‘–_ _,ğ‘_ _ğ‘–_ _,ğ‘_ _ğ‘–_ ) âˆˆ F [3] _,ğ‘_ _ğ‘–_ - _ğ‘_ _ğ‘–_ = _ğ‘_ _ğ‘–_ âˆˆ F . Since the other clients will verify the
proof, client C _ğ‘–_ then splits the proof to generate shares _ğœ‹_ _ğ‘–ğ‘—_ = [ï¿½] ( _ğ‘—,â„_ _ğ‘–ğ‘—_ ) _,_

( _ğ‘—,ğ‘_ _ğ‘–ğ‘—_ ) _,_ ( _ğ‘—,ğ‘_ _ğ‘–ğ‘—_ ) _,_ ( _ğ‘—,ğ‘_ _ğ‘–ğ‘—_ ) [ï¿½] for every other client C _ğ‘—_ âˆˆC \ _ğ‘–_ . The shares
themselves are generated via {(1 _,â„_ _ğ‘–_ 1 ) _,_ - Â· Â· _,_ ( _ğ‘–_ âˆ’ 1 _,â„_ _ğ‘–_ ( _ğ‘–_ âˆ’1) ) _,_ ( _ğ‘–_ + 1 _,â„_ _ğ‘–_ ( _ğ‘–_ +1) ) _,_

$

- Â· Â· _,_ ( _ğ‘›,â„_ _ğ‘–ğ‘›_ ) _,_ Î¨ _â„_ _ğ‘–_ } â†âˆ’ SS.share( _â„_ _ğ‘–_ _,_ [ _ğ‘›_ ] \ _ğ‘–,ğ‘š_ + 1), and so on. Finally, the

client encrypts the proof strings (shares of the update _ğ‘¢_ _ğ‘–_ and the
proof _ğœ‹_ _ğ‘–_ ) using the corresponding pairwise secret key, ( _ğ‘—,ğ‘¢_ _ğ‘–ğ‘—_ )||( _ğ‘—, ğœ‹_ _ğ‘–ğ‘—_ )

$
â†âˆ’ AE.enc [ï¿½] _ğ‘ ğ‘˜_ _ğ‘–ğ‘—_ _,_ ( _ğ‘—,ğ‘¢_ _ğ‘–ğ‘—_ )||( _ğ‘—, ğœ‹_ _ğ‘–ğ‘—_ ) [ï¿½], and publishes the encrypted proof
strings on the public bulletin B . The client also publishes the check



strings Î¨ _ğ‘¢_ _ğ‘–_ and Î¨ _ğœ‹_ _ğ‘–_ = (Î¨ _â„_ _ğ‘–_ _,_ Î¨ _ğ‘_ _ğ‘–_ _,_ Î¨ _ğ‘_ _ğ‘–_ _,_ Î¨ _ğ‘_ _ğ‘–_ ) for verifying the validity of
the shares of _ğ‘¢_ _ğ‘–_ and _ğœ‹_ _ğ‘–_, respectively.


**Round 3 (Verify Proof)** . In this round, every client C _ğ‘–_ partakes
in the verification of the proofs _ğœ‹_ _ğ‘—_ of all other clients C _ğ‘—_ âˆˆC \ _ğ‘–_,
under the supervision of the server S . The goal of the server is to
identify the malicious clients, C _ğ‘€_ . To this end, the server maintains
a (partial) list, C [âˆ—] (initialized as an empty list), of clients it has so
far identified as malicious. The proof-verification round consists of
three phases as follows:


( _ğ‘–_ ) _Verifying the validity of the secret shares_ . First, every client C _ğ‘–_
downloads and decrypts their shares from the bulletin B, ( _ğ‘–,ğ‘¢_ _ğ‘—ğ‘–_ )||( _ğ‘–, ğœ‹_ _ğ‘—ğ‘–_ )
â† AE.dec [ï¿½] _ğ‘ ğ‘˜_ _ğ‘–ğ‘—_ _,_ ( _ğ‘–,ğ‘¢_ _ğ‘—ğ‘–_ )||( _ğ‘–, ğœ‹_ _ğ‘—ğ‘–_ ) [ï¿½] _,_ âˆ€C _ğ‘—_ âˆˆC \ _ğ‘–_ . Additionally, C _ğ‘–_ downloads
the check strings (Î¨ _ğ‘¢_ _ğ‘–_ _,_ Î¨ _ğœ‹_ _ğ‘–_ ) and verifies the validity of the shares. If
the shares from any client C _ğ‘—_ :

- fail to be decrypted, _i.e._, AE.dec(Â·) outputs âŠ¥, OR

- fail to pass the verification, _i.e._, SS.verify(Â·) returns 0,

C _ğ‘–_ flags C _ğ‘—_ on the bulletin B . Every time a client C _ğ‘–_ flags another
client C _ğ‘—_, the server updates the corresponding list Flag[ _ğ‘—_ ]â† Flag[ _ğ‘—_ ] âˆªC _ğ‘–_ .
If |Flag[ _ğ‘—_ ]| â‰¥ _ğ‘š_ + 1, the server S marks C _ğ‘—_ as malicious: C [âˆ—] â†C [âˆ—] âˆªC _ğ‘—_ .
The server can do so because the pigeon hole principle implies that
C _ğ‘—_ must have sent an invalid share to at least one honest client;
hence, the correctness of the value recovered from that clientâ€™s
shares cannot be guaranteed. In case 1 â‰¤|Flag[ _ğ‘—_ ]| â‰¤ _ğ‘š_, the server
supervises the following actions. Suppose client C _ğ‘–_ has flagged
client C _ğ‘—_ . Client C _ğ‘—_ then reveals the shares for C _ğ‘–_, [ï¿½] ( _ğ‘–,ğ‘¢_ _ğ‘—ğ‘–_ ) _,_ ( _ğ‘–, ğœ‹_ _ğ‘—ğ‘–_ ) [ï¿½] in
the clear (on bulletin B ) for the server S (or anyone else) to verify
using SS.Verify(Â·) . If that verification passes, C _ğ‘–_ is instructed by the
server to use the released shares for its computations. Otherwise,
C _ğ‘—_ is marked as malicious by the server S . Note that this does not
lead to privacy violation for an honest client since at most _ğ‘š_ shares
corresponding to the _ğ‘š_ malicious clients would be revealed (see Sec.
5). If a client C _ğ‘–_ flags â‰¥ _ğ‘š_ + 1 other clients, S marks C _ğ‘–_ as malicious.
Thus, at this point every client on the list C [âˆ—] has either

- provided invalid shares to at least one honest client, OR

- flagged an honest client.
In other words, every client who is _not_ in C [âˆ—], C _ğ‘–_ âˆˆC \ C [âˆ—], is guaranteed to have submitted at least _ğ‘›_ âˆ’ _ğ‘š_ âˆ’1 valid shares for the honest

clients in C _ğ»_ \ C _ğ‘–_ (see Sec. 5 for details). Additionally, the server
cannot be tricked into marking an honest client as malicious, _i.e._,
EIFFeL ensures C [âˆ—] âˆ©C _ğ»_ = âˆ… (see Sec. 5). The server S publishes C [âˆ—]

on the bulletin B.


( _ğ‘–ğ‘–_ ) _Computation of proof summaries by clients._ For this phase, the
server S advertises a random value _ğ‘Ÿ_ âˆˆ F on the bulletin B . Next, a
client C _ğ‘–_ proceeds to distill the proof strings of all clients _not_ in C [âˆ—] to
generate summaries for the server S . Specifically, client C _ğ‘–_ prepares
a proof summary _ğœ_ _ğ‘—ğ‘–_ = [ï¿½] ( _ğ‘–,ğ‘¤_ _[ğ‘œğ‘¢ğ‘¡]_ _ğ‘—ğ‘–_ [)] _[,]_ [ (] _[ğ‘–, ğœ†]_ _[ğ‘—ğ‘–]_ [)][ï¿½] [for] [ âˆ€C] _[ğ‘—]_ [âˆˆC \ (C] [âˆ—] [âˆªC] _[ğ‘–]_ [)] [ as]
per the description in the previous section, and publishes it on B .


( _ğ‘–ğ‘–ğ‘–_ ) _Verification of proof summaries by the server._ Next, the server
moves to the last step of verifying the proof summaries _ğœ_ _ğ‘–_ = ( _ğ‘¤_ _ğ‘–_ _[ğ‘œğ‘¢ğ‘¡]_ _, ğœ†_ _ğ‘–_ )
for all clients not in C [âˆ—] . Recall from the discussion in Sec. 4.1 that
this involves recovering the values _ğ‘¤_ _ğ‘–_ _[ğ‘œğ‘¢ğ‘¡]_ and _ğœ†_ _ğ‘–_ from the shares
of _ğœ_ _ğ‘–_ and checking whether _ğ‘¤_ _ğ‘–_ _[ğ‘œğ‘¢ğ‘¡]_ = 1 and _ğœ†_ _ğ‘–_ = 0 . However, we cannot simply use the naive share reconstruction algorithm from Sec.
4.1 since some of the shares might be incorrect (submitted by the


E FFeL: Ensuring Integrity For Federated Learning CCS â€™22, November 7â€“11, 2022, Los Angeles, CA, USA



malicious clients). To address this issue, EIFFeL performs a _robust_
_reconstruction_ of the shares as follows. A naive strategy would be
sampling multiple subsets of _ğ‘š_ + 1 shares (each subset can emulate a SNIP setting), reconstructing the secret for each subset, and
taking the majority vote. However, we can do much better by exploiting the connections between Shamirâ€™s secret shares and ReedSolomon error correcting codes (Sec. 4.1). Specifically, the Shamirâ€™s
secret sharing scheme used by EIFFeL is a [ _ğ‘›_ âˆ’1 _,ğ‘š_ + 1 _,ğ‘›_ âˆ’ _ğ‘š_ ] ReedSolomon code that can correct up to _ğ‘_ errors and _ğ‘’_ erasures (message
dropouts) where 2 _ğ‘_ + _ğ‘’_ _< ğ‘›_ âˆ’ _ğ‘š_ âˆ’1 . The server S can, therefore, use
SS.robustRecon(Â·) to reconstruct the secret when _ğ‘š_ _<_ âŒŠ _[ğ‘›]_ [âˆ’] ~~3~~ [1] [âŒ‹] [.]


After the robust reconstruction of the proof summaries, the server
S verifies them and updates the list C [âˆ—] with _all_ malicious clients
with malformed updates. Specifically:
âˆ€C _ğ‘–_ âˆˆC \ C [âˆ—]
ï¿½SS.robustRecon ({( _ğ‘—,ğ‘¤_ _ğ‘–ğ‘—_ _[ğ‘œğ‘¢ğ‘¡]_ [)}] [C] _ğ‘—_ [âˆˆC\{C] [âˆ—] [âˆªC] _ğ‘–_ [}] [)][ â‰ ] [1][ âˆ¨]

SS.robustRecon ({( _ğ‘—, ğœ†_ _ğ‘–ğ‘—_ )} C _ğ‘—_ âˆˆC\{C âˆ— âˆªC _ğ‘–_ } ) â‰  0 ï¿½

=â‡’C [âˆ—] â†C [âˆ—] âˆªC _ğ‘–_ _._


Additionally, if a client C _ğ‘–_ withholds some of the shares of the proof
summaries for other clients, C _ğ‘–_ is marked as malicious as well by
the server. Thus, in addition to the malicious clients listed above,
the list C [âˆ—] now has all clients that have either:

- failed the proof verification, _i.e._, provided malformed updates,
OR

- withheld shares of proof summaries of other clients (malicious
message dropout).
To conclude the round, the server publishes the updated list C [âˆ—] on
the public bulletin B.


**Round 4 (Compute Aggregate).** This is the final round of EIFFeL where the aggregate of the well-formed updates is computed.
If a client C _ğ‘–_ is on C [âˆ—] wrongfully, it can dispute its malicious status
by showing the other clients the transcript of the robust reconstruction from all the shares of _ğœ_ _ğ‘–_ (publicly available on bulletin B ). If
any client C _ğ‘–_ âˆˆC successfully raises a dispute, all clients abort
the protocol because they conclude that the server S has acted
maliciously by trying to withhold a verified well-formed update
from the aggregation. If no client raises a successful dispute, every
client C _ğ‘–_ âˆˆC \ C [âˆ—] generates its share of the aggregate, ( _ğ‘–,_ U _ğ‘–_ ) with
U _ğ‘–_ = [ï¿½] C _ğ‘—_ âˆˆC\C [âˆ—] _[ğ‘¢]_ _ğ‘—ğ‘–_ [, and sends that share to the server] [ S] [. Note that,]
herein, C _ğ‘–_ uses its own share of the update, ( _ğ‘–,ğ‘¢_ _ğ‘–ğ‘–_ ), as well.
The server recovers the aggregate U = [ï¿½] C _ğ‘–_ âˆˆC\C [âˆ—] [U] _ğ‘—_ [using robust]
reconstruction: U â† SS.robustRecon({( _ğ‘–,_ U _ğ‘–_ )} C _ğ‘–_ âˆˆC\C âˆ— ) .


**Discussion.** EIFFeL meets the design goals of Sec. 4.3 as follows.

_Flexibility of Integrity Checks._ SNIP supports arbitrary arithmetic
circuits for Valid(Â·) . The server S can choose a different Valid(Â·) for
every iteration (the protocol described above corresponds to a single
iteration of model training in FL). Additionally, S can hold multiple
Valid 1 (Â·) _,_ - Â· Â· _,_ Valid _ğ‘˜_ (Â·) and want to check whether the clientâ€™s update passes them all. For this, we have Valid _ğ‘–_ (Â·) return zero (instead
of one) on success. If _ğ‘¤_ _ğ‘–_ _[ğ‘œğ‘¢ğ‘¡]_ is the value on the output wire of the
circuit Valid _ğ‘–_ (Â·), the server chooses random values ( _ğ‘™_ 1 _,_ - Â· Â· _,ğ‘™_ _ğ‘˜_ ) âˆˆ F _[ğ‘˜]_

and recovers the sum [ï¿½] _[ğ‘˜]_ _ğ‘–_ =1 _[ğ‘™]_ _[ğ‘–]_ [Â·] _[ ğ‘¤]_ _ğ‘–_ _[ğ‘œğ‘¢ğ‘¡]_ in Round 3. If any _ğ‘¤_ _ğ‘–_ _[ğ‘œğ‘¢ğ‘¡]_ = 0, then
the sum will be non-zero with high probability and S will reject.



_Compatibility with FLâ€™s Infrastructure._ Current deployments of FL
involves a _single_ server who wants to train the global model. Hence,
as explained above, we design SNIP to be compatible with a single
server in EIFFeL. Solutions involving two or more non-colluding
servers are unrealistic for FL. For instance, currently the server can
be owned by Meta who wants to train privately on the data of its
user base. For a two-server model here, the second server has to be
owned by an independent party. Moreover, both the servers have to
do an equal amount of computation for model training (verification,
aggregation etc) since SNIP uses secret shares. This would make
sense only if _both_ the servers are interested in training the model.
For instance, if Meta and Google collaborate to train a model on
their joint user base which is an unrealistic scenario.


_Efficiency._ EIFFeLâ€™s usage of SNIP as the underlying ZKP is made
from the efficiency point of view. SNIP is a light-weight ZKP system that is _specialized for the server-client settings_ resulting in good
performance. For instance, its performance is about three-orders
of magnitude better than that of zkSNARKs [ 28 ]. Instead of using ZKPs, one alternative is to use standard secure multi-party
computation (MPC) for the entire aggregation to directly compute
U _ğ‘£ğ‘ğ‘™ğ‘–ğ‘‘_ = [ï¿½] C _ğ‘–_ [Valid][(] _[ğ‘¢]_ _ğ‘–_ [) Â·] _[ ğ‘¢]_ _ğ‘–_ [. However, doing the entire aggregation]
under MPC would result in a massive circuit with _ğ‘‚_ ( _ğ‘›ğ‘‘_ ) multiplication gates where _ğ‘‘_ is the data dimension. Multiplications are
costly for MPC and each gate requires a round of communication
in general making the above computation prohibitively costly. Extending the computation to the malicious threat model would be
even costlier. This is where SNIP proves to be advantageous: SNIP
enables the verifiers to check all the multiplication gates very efficiently (in a non-interactive fashion) with just one polynomial
identity test (Sec. 4.1).




CCS â€™22, November 7â€“11, 2022, Los Angeles, CA, USA Roy Chowdhury et al.



**Computation** **Communication**


**Client** _ğ‘‚_ ( _ğ‘šğ‘›ğ‘‘_ ) _ğ‘‚_ ( _ğ‘šğ‘›ğ‘‘_ )
**Server** _ğ‘‚_ [ï¿½] ( _ğ‘›_ + _ğ‘‘_ ) _ğ‘›_ log [2] _ğ‘›_ log log _ğ‘›_ + _ğ‘šğ‘‘_ min( _ğ‘›,ğ‘š_ [2] ) [ï¿½] _ğ‘‚_ [ï¿½] _ğ‘›_ [2] + _ğ‘šğ‘‘_ min( _ğ‘›,ğ‘š_ [2] ) [ï¿½]


**Table 1: Computational and communication complexity of EIF-**
**FeL for the server and an individual client.**



valid shares. Hence, at least _ğ‘›_ âˆ’ _ğ‘š_ âˆ’ 1 other honest clients C _ğ»_ \ C _ğ‘–_
will produce correct shares of the proof summary _ğœ_ _ğ‘–_ = ( _ğ‘¤_ _ğ‘–_ _[ğ‘œğ‘¢ğ‘¡]_ _, ğœ†_ _ğ‘–_ ) .
Using Fact 2, the server S is able to correctly reconstruct the value
of _ğœ_ _ğ‘–_ . Eq. 4 is now implied by the completeness property of SNIP.

                     

Lemma 3. _All updates accepted by EIFFeL are well-formed with prob-_
_ability_ 1 âˆ’ negl( _ğœ…_ ) _._





âˆ€C _ğ‘–_ âˆˆC _,_ Pr
_EIFFeL_



ï¿½ _Valid_ ( _ğ‘¢_ _ğ‘–_ ) = 1 ï¿½ï¿½ _Accept_ _ğ‘¢_ _ğ‘–_ ï¿½ = 1 âˆ’ negl( _ğœ…_ ) _._ (5)



Table 1 analyses the complexity of EIFFeL in terms of the number
of clients _ğ‘›_, number of malicious clients _ğ‘š_ and data dimension _ğ‘‘_ .
We assume that |Valid| is of the order of _ğ‘‚_ ( _ğ‘‘_ ) . The total number of
one-way communication is 12 and 9 for the clients and the server,
respectively. A per-round analysis is presented in App. 11.2.


**5** **Security Analysis**


In this section, we formally analyze the security of EIFFeL.


Theorem 1. _For any public validation predicate_ _Valid_ (Â·) _that can be_
_expressed by an arithmetic circuit, EIFFeL is a SAVI protocol (Def. 1)_
_for_ |C _ğ‘€_ | _<_ âŒŠ _[ğ‘›]_ [âˆ’] ~~3~~ [1] [âŒ‹] _[and]_ [ C] _[Valid]_ [=][ C \ C] [âˆ—] _[.]_


We present a proof sketch of the above theorem here; the formal
proof is in App. 11.5.


_Proof Sketch._ The proof relies on the following two facts.
**Fact 1.** _Any set of_ _ğ‘š_ _or less shares in EIFFeL reveals nothing about_
_the secret._

**Fact 2.** _A_ ( _ğ‘›,ğ‘š_ + 1 _,ğ‘›_ âˆ’ _ğ‘š_ ) _Reed-Solomon error correcting code can_
_correctly construct the message with up to_ _ğ‘_ _errors and_ _ğ‘’_ _erasures_
_(message dropout), where_ 2 _ğ‘_ + _ğ‘’_ _< ğ‘›_ âˆ’ _ğ‘š_ + 1 _. In EIFFeL, we have_ _ğ‘_ + _ğ‘’_ = _ğ‘š_
_where_ _ğ‘_ _is the number of malicious clients that provide erroneous_
_shares and_ _ğ‘’_ _is the number of clients that withhold a message or are_
_barred from participation (_ i.e. _, are in_ C [âˆ—] _)._


_Integrity._ We prove that EIFFeL satisfies the integrity constraint of
the SAVI protocol using the following three lemmas.


Lemma 2. _EIFFeL accepts the update of every honest client._


âˆ€C _ğ‘–_ âˆˆC _ğ»_ : Pr (4)
_EIFFeL_ [[] _[Accept][ ğ‘¢]_ _[ğ‘–]_ []][ =][ 1] _[.]_


Proof. By definition, client C _ğ‘–_ âˆˆC _ğ»_ has well-formed inputs, that
is, Valid( _ğ‘¢_ _ğ‘–_ ) = 1. Additionally, C _ğ‘–_, by virtue of being honest, submits



The proof relies on the fact that a client will be verified only if it
has submitted â‰¥ _ğ‘›_ âˆ’ _ğ‘š_ âˆ’ 1 valid shares (see App. 11.3).
Corollary 3.1. _EIFFeL rejects all malformed updates with probabil-_
_ity_ 1 âˆ’ negl( _ğœ…_ ) _._


Based on the above lemmas, at the end of Round 3, C \ C [âˆ—] (set
of clients whose updates have been accepted) must contain _all_
honest clients C _ğ»_ . Additionally, it may contain some clients C _ğ‘–_
who have submitted well-formed updates with at least _ğ‘›_ âˆ’ _ğ‘š_ âˆ’ 1
valid shares for C _ğ»_, but may act maliciously for other steps of the
protocol (for instance, give incorrect shares of proof summary for
other clients or give incorrect shares of the final aggregate). This
is acceptable provided that EIFFeL is able to reconstruct the final
aggregate containing _only_ well-formed updates which is guaranteed
by the following lemma.
Lemma 4. _The aggregate_ U _must contain the updates of all honest_
_clients or the protocol is aborted._



C âŠ†C \ {CÂ¯ [âˆ—] âˆªC _ğ»_ } (6)


Proof. If the server S acts maliciously and publishes a list C [âˆ—]

such that C [âˆ—] âˆ©C _ğ»_ â‰  âˆ…, an honest client C _ğ‘–_ âˆˆC [âˆ—] âˆ©C _ğ»_ publicly raises
a dispute. This is possible since all the shares of _ğœ_ _ğ‘–_ are publicly
logged on B . If the dispute is successful, all honest clients will
abort the protocol. Note that a malicious client with malformed
updates cannot force the protocol to abort in this way since it will
not be able to produce a successful transcript with high probability
(Lemma 3). If no clients raise a successful dispute, Eq. 6 follows
directly from Fact 2. C [Â¯] represents a set of malicious clients with
well-formed updates which corresponds to C Valid \ C _ğ»_ in Eq. 3. 

_Privacy._ The privacy constraint of SAVI states that nothing should be
revealed about a private update _ğ‘¢_ _ğ‘–_ for an honest client C _ğ‘–_, except:

- _ğ‘¢_ _ğ‘–_ passes the integrity check, _i.e._, Valid( _ğ‘¢_ _ğ‘–_ ) = 1

- anything that can be learned from the aggregate of honest clients,
U _ğ»_ .
We prove that EIFFeL satisfies this privacy constraint with the help
of the following two helper lemmas.


Lemma 5. _In Rounds 1-3, for an honest client_ C _ğ‘–_ âˆˆC _ğ»_ _, EIFFeL reveals_
_nothing about ğ‘¢_ _ğ‘–_ _except Valid_ ( _ğ‘¢_ _ğ‘–_ ) = 1 _._
The proof uses the fact that only _ğ‘š_ shares of C _ğ‘–_, which correspond
to the _ğ‘š_ malicious clients, can be revealed (see App. 11.4).


Lemma 6. _In Round_ 4 _, for an honest client_ C _ğ‘–_ âˆˆC _ğ»_ _, EIFFeL reveals_
_nothing about_ _ğ‘¢_ _ğ‘–_ _except whatever can be learned from the aggregate._

Proof. In Round 4, from Lemma 4 and Fact 2, the information
revealed is either the aggregate or âŠ¥. 


U = U _ğ»_ +
âˆ‘ï¸



_ğ‘¢_ _ğ‘–_ _where_ U _ğ»_ =

âˆ‘ï¸ âˆ‘ï¸

C _ğ‘–_ âˆˆ C [Â¯] C _ğ‘–_ âˆˆC



_ğ‘¢_ _ğ‘–_

C _ğ‘–_ âˆˆC _ğ»_


E FFeL: Ensuring Integrity For Federated Learning CCS â€™22, November 7â€“11, 2022, Los Angeles, CA, USA


 - **Setup Phase.**

**â€“** All parties are given the security parameter _ğœ…_, the number of clients _ğ‘›_ out of which at most _ğ‘š_ _<_ âŒŠ _[ğ‘›]_ 3 [âˆ’][1] [âŒ‹] [are malicious, honestly generated] _[ ğ‘ğ‘]_ â†âˆ’ $ KA.gen( _ğœ…_ )

and a field F to be used for secret sharing. Server initializes lists Flag[ _ğ‘–_ ] = âˆ… _,ğ‘–_ âˆˆ[ _ğ‘›_ ] and C [âˆ—] = âˆ… .

 - **Round 1 (Announcing Public Information).**
_Client_ : Each client C _ğ‘–_

**â€“** Generates its key pair and announces the public key. ( _ğ‘ğ‘˜_ _ğ‘–_ _,ğ‘ ğ‘˜_ _ğ‘–_ ) â†âˆ’ $ KA.gen( _ğ‘ğ‘_ ), C _ğ‘–_ âˆ’âˆ’âˆ’â†’B _ğ‘ğ‘˜_ _ğ‘–_ .

_Server_ :

**â€“** Publishes the validation predicate Valid(Â·). S âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’B Valid(Â·)

 - **Round 2 (Generate and Distribute Proof).**
_Client_ : Each client _ğ¶_ _ğ‘–_
**â€“** Computes _ğ‘›_ âˆ’ 1 pairwise keys. âˆ€C _ğ‘—_ âˆˆC \ _ğ‘–_ _,ğ‘ ğ‘˜_ _ğ‘–ğ‘—_ â† KA.agree( _ğ‘ğ‘˜_ _ğ‘—_ _,ğ‘ ğ‘˜_ _ğ‘–_ )
**â€“** Generates proof _ğœ‹_ _ğ‘–_ = [ï¿½] _â„_ _ğ‘–_ _,_ ( _ğ‘_ _ğ‘–_ _,ğ‘_ _ğ‘–_ _,ğ‘_ _ğ‘–_ ) [ï¿½] _,â„_ _ğ‘–_ âˆˆ F[ _ğ‘‹_ ] _,_ ( _ğ‘_ _ğ‘–_ _,ğ‘_ _ğ‘–_ _,ğ‘_ _ğ‘–_ ) âˆˆ F [3] _, ğ‘_ _ğ‘–_   - _ğ‘_ _ğ‘–_ = _ğ‘_ _ğ‘–_ for the statement Valid( _ğ‘¢_ _ğ‘–_ ) = 1.

**â€“** Generates shares of the input _ğ‘¢_ _ğ‘–_ âˆˆ F _[ğ‘‘]_ . {(1 _,ğ‘¢_ _ğ‘–_ 1 ) _,_   - Â· Â· _,_ ( _ğ‘›,ğ‘¢_ _ğ‘–ğ‘›_ ) _,_ Î¨ _ğ‘¢_ _ğ‘–_ } â†âˆ’ $ SS.share( _ğ‘¢_ _ğ‘–_ _,_ [ _ğ‘›_ ] _,ğ‘š_ + 1)
**â€“** Generates shares of the proof _ğœ‹_ _ğ‘–_ . $ $
{(1 _,â„_ _ğ‘–_ 1 ) _,_            - Â· Â· _,_ ( _ğ‘›,â„_ _ğ‘–ğ‘›_ ) _,_ Î¨ _â„_ _ğ‘–_ } â†âˆ’ SS.share( _â„_ _ğ‘–_ _,_ [ _ğ‘›_ ] \ _ğ‘–,ğ‘š_ + 1) _,_ {(1 _,ğ‘_ _ğ‘–_ 1 ) _,_            - Â· Â· _,_ ( _ğ‘›,ğ‘_ _ğ‘–ğ‘›_ ) _,_ Î¨ _ğ‘_ _ğ‘–_ } â†âˆ’ SS.share( _ğ‘_ _ğ‘–_ _,_ [ _ğ‘›_ ] \ _ğ‘–,ğ‘š_ + 1)


$ $
{(1 _,ğ‘_ _ğ‘–_ 1 ) _,_            - Â· Â· _,_ ( _ğ‘›,ğ‘_ _ğ‘–ğ‘›_ ) _,_ Î¨ _ğ‘_ _ğ‘–_ } â†âˆ’ SS.share( _ğ‘_ _ğ‘–_ _,_ [ _ğ‘›_ ] \ _ğ‘–,ğ‘š_ + 1) _,_ {(1 _,ğ‘_ _ğ‘–_ 1 ) _,_            - Â· Â· _,_ ( _ğ‘›,ğ‘_ _ğ‘–ğ‘›_ ) _,_ Î¨ _ğ‘_ _ğ‘–_ } â†âˆ’ SS.share( _ğ‘_ _ğ‘–_ _,_ [ _ğ‘›_ ] \ _ğ‘–,ğ‘š_ + 1)

**â€“** Encrypts proof strings for all other clients. âˆ€C _ğ‘—_ âˆˆC \ _ğ‘–_ _,_ ( _ğ‘—,ğ‘¢_ _ğ‘–ğ‘—_ ) ||( _ğ‘—, ğœ‹_ _ğ‘–ğ‘—_ ) â†âˆ’ $ AE.enc [ï¿½] _ğ‘ ğ‘˜_ _ğ‘–ğ‘—_ _,_ ( _ğ‘—,ğ‘¢_ _ğ‘–ğ‘—_ ) ||( _ğ‘—, ğœ‹_ _ğ‘–ğ‘—_ ) [ï¿½] _, ğœ‹_ _ğ‘–ğ‘—_ = _â„_ _ğ‘–ğ‘—_ || _ğ‘_ _ğ‘–ğ‘—_ || _ğ‘_ _ğ‘–ğ‘—_ || _ğ‘_ _ğ‘–ğ‘—_ .

**â€“** Publishes check strings and the encrypted proof strings on the bulletin. âˆ€C _ğ‘—_ âˆˆC \ _ğ‘–_ _,_ C _ğ‘–_ âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’B ( _ğ‘—,ğ‘¢_ _ğ‘–ğ‘—_ )||( _ğ‘—,ğœ‹_ _ğ‘–ğ‘—_ ) ; C _ğ‘–_ âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’B Î¨ _ğ‘¢ğ‘–_ _,_ Î¨ _ğœ‹ğ‘–_

 - **Round 3 (Verify Proof)** .
(i) _Verifying validity of secret shares_ :
_Client_ : Each client C _ğ‘–_
**â€“** Downloads and decrypts proof strings for all other clients from the public bulletin. Flags a client in case their decryption fails.



âˆ€C _ğ‘—_ âˆˆC \ _ğ‘–_ _,_ C _ğ‘–_



( _ğ‘–,ğ‘¢_ _ğ‘—ğ‘–_ )||( _ğ‘–,ğœ‹_ _ğ‘—ğ‘–_ ) _,_ Î¨ _ğ‘¢ğ‘—_ _,_ Î¨ _ğœ‹ğ‘—_
â†âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’B _,_ ( _ğ‘–,ğ‘¢_ _ğ‘—ğ‘–_ ) ||( _ğ‘–, ğœ‹_ _ğ‘—ğ‘–_ ) â† AE.dec [ï¿½] _ğ‘ ğ‘˜_ _ğ‘–ğ‘—_ _,_ ( _ğ‘–,ğ‘¢_ _ğ‘—ğ‘–_ ) ||( _ğ‘–, ğœ‹_ _ğ‘—ğ‘–_ ) [ï¿½]


Flag C _ğ‘—_
âŠ¥â† AE.dec [ï¿½] _ğ‘ ğ‘˜_ _ğ‘–ğ‘—_ _,_ ( _ğ‘–,ğ‘¢_ _ğ‘—ğ‘–_ ) ||( _ğ‘–, ğœ‹_ _ğ‘—ğ‘–_ ) [ï¿½] =â‡’ _ğ¶ğ‘™_ _ğ‘–_ âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’B



**â€“** Verifies the shares _ğ‘¢_ _ğ‘—ğ‘–_ ( _ğœ‹_ _ğ‘—ğ‘–_ ) using checkstrings Î¨ _ğ‘¢_ _ğ‘—_ (Î¨ _ğœ‹_ _ğ‘—_ ) and flags all clients with invalid shares. Flag C _ğ‘—_
_Server_ : âˆ€C _ğ‘—_ âˆˆC \ _ğ‘–_ _,_ 0 â† [ï¿½] SS.verify(( _ğ‘–,ğ‘¢_ _ğ‘—ğ‘–_ ) _,_ Î¨ _ğ‘¢_ _ğ‘—_ ) âˆ§ SS.verify(( _ğ‘–, ğœ‹_ _ğ‘—ğ‘–_ ) _,_ Î¨ _ğœ‹_ _ğ‘—_ ) [ï¿½] =â‡’C _ğ‘–_ âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’B
**â€“** If client C _ğ‘–_ flags client C _ğ‘—_, the server updates Flag[ _ğ‘—_ ] = Flag[ _ğ‘—_ ] âˆªC _ğ‘–_
**â€“** Updates the list of malicious client C [âˆ—] as follows:

   - Adds all clients who have flagged â‰¥ _ğ‘š_ + 1 other clients. âˆ€C _ğ‘–_ s. t. _ğ‘_ = { _ğ‘—_ |C _ğ‘–_ âˆˆ Flag[ _ğ‘—_ ]} _,_ | _ğ‘_ | â‰¥ _ğ‘š_ + 1 =â‡’C [âˆ—] â†C [âˆ—] âˆªC _ğ‘–_

   - Adds all clients with more than _ğ‘š_ + 1 flag reports. |Flag[ _ğ‘–_ ] | â‰¥ _ğ‘š_ + 1 =â‡’C [âˆ—] â†C [âˆ—] âˆªC _ğ‘–_

   - For clients with less flag reports, the server obtains the corresponding shares in the clear, verifies them and updates C [âˆ—] accordingly. âˆ€C _ğ‘—_ s.t 1 â‰¤
|Flag[ _ğ‘—_ ] | â‰¤ _ğ‘š,_ âˆ€C _ğ‘–_ s.t. C _ğ‘–_ has flagged C _ğ‘—_

( _ğ‘–,ğ‘¢_ _ğ‘—ğ‘–_ ) _,_ ( _ğ‘–,ğœ‹_ _ğ‘—ğ‘–_ )
âˆ’C _ğ‘—_ âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’B
âˆ’ if [ï¿½] SS.verify(( _ğ‘–,ğ‘¢_ _ğ‘—ğ‘–_ ) _,_ Î¨ _ğ‘¢_ _ğ‘—_ ) âˆ§ SS.verify(( _ğ‘–, ğœ‹_ _ğ‘—ğ‘–_ ) _,_ Î¨ _ğœ‹_ _ğ‘—_ ) [ï¿½] = 0 =â‡’C [âˆ—] â†C [âˆ—] âˆªC _ğ‘—_ _,_ otherwise, C _ğ‘–_ uses the verified shares to compute its proof

summary _ğœ_ _ğ‘—ğ‘–_
C [âˆ—]
**â€“** Publishes C [âˆ—] on the bulletin. S âˆ’âˆ’â†’B

(ii) _Generation of proof summaries by the clients._

_Server_ :

_ğ‘Ÿ_
**â€“** Server announces a random number _ğ‘Ÿ_ âˆˆ F. S âˆ’â†’B

_Client_ : Each client C _ğ‘–_ âˆˆC \ C [âˆ—]

**â€“** Generates a summary _ğœ_ _ğ‘—ğ‘–_ of the proof string _ğœ‹_ _ğ‘—ğ‘–_ based on _ğ‘Ÿ_, âˆ€C _ğ‘—_ âˆˆC \ (C [âˆ—] âˆªC _ğ‘–_ ) _,_ C _ğ‘–_ â†âˆ’B _ğ‘Ÿ_ _, ğœ_ _ğ‘—ğ‘–_ = [ï¿½] ( _ğ‘–, ğ‘¤_ _ğ‘œğ‘¢ğ‘¡ğ‘—ğ‘–_ ) _,_ ( _ğ‘–, ğœ†_ _ğ‘—ğ‘–_ ) [ï¿½] _,_ C _ğ‘–_ âˆ’âˆ’âˆ’â†’B _ğœ_ _ğ‘—ğ‘–_
(iii) _Verification of proof summaries by the server._

_Server_ :

**â€“** Downloads and verifies the proof for all clients not on C [âˆ—] via robust reconstruction of the digests and updates C [âˆ—] accordingly.

_ğœ_ _ğ‘–ğ‘—_
âˆ€C _ğ‘–_ âˆˆC \ C [âˆ—] _,_ S â†âˆ’âˆ’âˆ’B _,_ [ï¿½] SS.robustRecon({( _ğ‘—, ğ‘¤_ _ğ‘–ğ‘—_ _[ğ‘œğ‘¢ğ‘¡]_ ) } C _ğ‘—_ âˆˆC\(C âˆ— âˆªC _ğ‘–_ ) ) â‰  1 âˆ¨ SS.robustRecon({( _ğ‘—, ğœ†_ _ğ‘–ğ‘—_ ) } C _ğ‘—_ âˆˆC\(C âˆ— âˆªC _ğ‘–_ ) ) â‰  0 [ï¿½] =â‡’C [âˆ—] â†C [âˆ—] âˆªC _ğ‘–_

C [âˆ—]
**â€“** Publishes the updated list C [âˆ—] on the bulletin. S âˆ’âˆ’â†’B

- **Round 4 (Compute Aggregate).**
_Client_ : Each client C _ğ‘–_
**â€“** If C _ğ‘–_ is on C [âˆ—], C _ğ‘–_ raises a dispute by sending the transcript of the reconstruction of _ğœ_ _ğ‘–_ that shows _ğœ†_ _ğ‘–_ = 0 âˆ§ _ğ‘¤_ _[ğ‘œğ‘¢ğ‘¡]_ _ğ‘—_ = 1 and aborts, OR

_ğœ_ _ğ‘–ğ‘—_ Transcript of SS.robustRecon({( _ğ‘—,ğœ_ _ğ‘–ğ‘—_ )} C _ğ‘—_ âˆˆC\(Câˆ—âˆªC _ğ‘–_ ) )
âˆ€C _ğ‘—_ âˆˆC \ _ğ‘–_ _,_ C _ğ‘–_ â†âˆ’âˆ’âˆ’B _,_ C _ğ‘–_ âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’B
**â€“** Aborts protocol if it sees any other client on C [âˆ—] successfully raise a dispute, OR

**â€“** If no client has raised a dispute and C _ğ‘–_ is not on C [âˆ—], sends the aggregate of the shares of clients in C \ C [âˆ—] to the server. U _ğ‘–_ = [ï¿½] _ğ‘¢_ _ğ‘—ğ‘–_ âˆ’âˆ’â†’S U _ğ‘–_
_Server_ : C _ğ‘—_ âˆˆC\C [âˆ—] _[,]_ [ C] _[ğ‘–]_
**â€“** Reconstructs the final aggregate. U â† SS.robustRecon({( _ğ‘–,_ U _ğ‘–_ ) } C _ğ‘–_ âˆˆC\C âˆ— )


**Figure 4: EIFFeL: Description of the secure aggregation with verified inputs protocol.**


CCS â€™22, November 7â€“11, 2022, Los Angeles, CA, USA Roy Chowdhury et al.



**6** **EIFFeL Optimizations**


**6.1** **Probabilistic Reconstruction**


The Gaoâ€™s decoding algorithm alongside the use of verifiable secret
sharing guarantees that the correct secret will be recovered (with
probability one). However, we can improve performance at the cost
of a small probability of failure.


**Verifying Secret Shares.** As discussed in Sec. 11.2, verifying the
validity of the secret shares is the dominating cost for client-side
computation. To reduce this cost, we propose an optimization
where the validation of the shares corresponding to the proof
_ğœ‹_ _ğ‘–_ = [ï¿½] _â„_ _ğ‘–_ _,_ ( _ğ‘_ _ğ‘–_ _,ğ‘_ _ğ‘–_ _,ğ‘_ _ğ‘–_ ) [ï¿½] can be eliminated. Specifically, we propose the
following changes to Round 3:


- Each client C _ğ‘–_ skips verifying the validity of the shares ( _ğ‘–, ğœ‹_ _ğ‘—ğ‘–_ )
for C _ğ‘—_ âˆˆC \ _ğ‘–_ .

- Let _ğ‘’_ = |C [âˆ—] | . The server S samples two sets of clients _ğ‘ƒ_ 1 _, ğ‘ƒ_ 2 from

C \ {C _ğ‘–_ âˆªC [âˆ—] } of size at least 3 _ğ‘š_ âˆ’ 2 _ğ‘’_ + 1 ( _ğ‘ƒ_ 1 _, ğ‘ƒ_ 2 can be overlapping) and performs Gaoâ€™s decoding on both the sets to obtain
polynomials _ğ‘_ 1 and _ğ‘_ 2 . The server accepts the _ğ‘¤_ _ğ‘–_ _[ğ‘œğ‘¢ğ‘¡]_ ( _ğœ†_ _ğ‘–_ ) only
iff _ğ‘_ 1 = _ğ‘_ 2 and _ğ‘_ 1 (0) = _ğ‘_ 1 (0) = 1( _ğ‘_ 1 (0) = _ğ‘_ 1 (0) = 0) . The cost of this
step is _ğ‘‚_ ( _ğ‘›_ [2] log [2] _ğ‘›_ log log _ğ‘›_ ) which is less than verifying the shares
of _ğœ‹_ _ğ‘–_ when _ğ‘š_ _< ğ‘›_ â‰ª _ğ‘‘_ (improves runtime by 2 _._ 3Ã—, see Table 2).


Note that a [ _ğ‘›,ğ‘˜,ğ‘›_ âˆ’ _ğ‘˜_ + 1] Reed-Solomon error correcting code can
correct up to âŒŠ _[ğ‘›]_ [âˆ’] ~~2~~ _[ğ‘˜]_ [âˆ’] _[ğ‘™]_ âŒ‹ errors with _ğ‘™_ erasures. Thus, with _ğ‘š_ âˆ’ _ğ‘’_ mali
cious clients, only 3 _ğ‘š_ âˆ’2 _ğ‘’_ +1 shares are sufficient to correctly reconstruct the secret for honest clients. Since, the random sets _ğ‘ƒ_ 1 and
_ğ‘ƒ_ 2 are not known, a malicious client with more than _ğ‘š_ âˆ’ _ğ‘’_ invalid
shares can cheat only with probability at most [1] /( [3] _[ğ‘š]_ _ğ‘›_ [âˆ’] âˆ’ [2] _ğ‘’_ _[ğ‘’]_ [+][2] [)] [. We cannot]
extend this technique for the secret shares of the update _ğ‘¢_, because,
unlike the value of the digests ( _ğ‘¤_ _[ğ‘œğ‘¢ğ‘¡]_ = 1 _, ğœ†_ = 0), the final aggregate is
unknown and needs to be reconstructed from the shares.


_Improvement._ Eliminates verification of check strings for the proof
_ğœ‹_ _ğ‘–_ which reduces time by 2 _._ 3Ã— (Table 2).
_Cost._ Additional [1] /( [3] _[ğ‘š]_ _ğ‘›_ [âˆ’] âˆ’ [2] _ğ‘’_ _[ğ‘’]_ [+][2] [)] [ probability of failure where] _[ ğ‘’]_ [=][ |] _[ğ¶]_ [âˆ—] [|] [ .]


**Robust Reconstruction.** In case _ğ‘š_ â‰¤ [âˆš] ~~_ğ‘›_~~ âˆ’ 2, the robust reconstruction mechanism can be optimized as follows. Let _ğ‘_ = _ğ‘š_ âˆ’|C [âˆ—] |
be the number of malicious clients that remain undetected. The
server S partitions the set of clients in C \ C [âˆ—] into at least _ğ‘_ + 2
disjoint partitions, _ğ‘ƒ_ = { _ğ‘ƒ_ 1 _,_ - Â· Â· _, ğ‘ƒ_ _ğ‘_ +2 } each of size _ğ‘š_ + 1. Let
_ğ‘_ _ğ‘—_ ( _ğ‘¥_ ) = _ğ‘_ _ğ‘—,_ 0 + _ğ‘_ _ğ‘—,_ 1 _ğ‘¥_ + _ğ‘_ _ğ‘—,_ 2 _ğ‘¥_ [2] + Â· Â· Â· + _ğ‘_ _ğ‘—,ğ‘š_ _ğ‘¥_ _[ğ‘š]_ represent the polynomial corresponding to the _ğ‘š_ + 1 shares of partition _ğ‘ƒ_ _ğ‘—_ . Recall
that recovering just _ğ‘_ _ğ‘—_ ( 0 ) = _ğ‘_ _ğ‘—,_ 0 suffices for a typical Shamir secret
share reconstruction. However, now, the server S recovers the entire polynomial _ğ‘_ _ğ‘—_, _i.e._, all of its coefficients { _ğ‘_ _ğ‘—,_ 0 _,ğ‘_ _ğ‘—,_ 1 _,_ - Â· Â· _,ğ‘_ _ğ‘—,ğ‘_ } for
all _ğ‘_ + 2 partitions. Based on the pigeon hole principle, it can be
argued that at least two of the partitions ( _ğ‘ƒ_ _ğ‘™_ _, ğ‘ƒ_ _ğ‘˜_ âˆˆ _ğ‘ƒ_ ) will consist of
_honest_ clients only. Hence, we must have at least two polynomials
_ğ‘_ _ğ‘™_ and _ğ‘_ _ğ‘˜_ that match and the value of the secret is their constant
coefficient _ğ‘_ _ğ‘™_ ( 0 ) . Note that the above mentioned optimization of
skipping verifying the shares of the proof can be applied here as
well. A malicious client can cheat ( _i.e._, make the server S accept
even when _ğ‘¤_ _ğ‘–_ _[ğ‘œğ‘¢ğ‘¡]_ â‰  1 âˆ¨ _ğœ†_ _ğ‘–_ â‰  0 or reject the proof for an honest client)
only if they can manipulate the shares of at least two partitions
which must contain at least 2( _ğ‘š_ + 1) âˆ’ _ğ‘_ honest clients. Since the



random partition _ğ‘ƒ_ is not known to the clients, this can happen
only with probability [1] /( [2][(] _ğ‘›_ _[ğ‘š]_ âˆ’ _ğ‘š_ [+][1] âˆ’ [)âˆ’] 1 _[ğ‘]_ [)][.]


_Improvement._ Reduces the number of polynomial interpolations.
_Cost._ Additional [1] /( [2][(] _ğ‘›_ _[ğ‘š]_ âˆ’ _ğ‘š_ [+][1] âˆ’ [)âˆ’] 1 _[ğ‘]_ [)] [ probability of failure where] _[ ğ‘]_ [=] _[ ğ‘š]_ [âˆ’|C] [âˆ—] [|] [ .]

**6.2** **Crypto-Engineering Optimizations**


**Equality Checks.** The equality operator = is relatively complicated to implement in an arithmetic circuit. To circumvent this issue,
we replace any validation check of the form Î¦( _ğ‘¢_ ) = _ğ‘_ 1 âˆ¨ Î¦( _ğ‘¢_ ) = _ğ‘_ 2 âˆ¨Â· Â· Â·
âˆ¨Î¦( _ğ‘¢_ ) = _ğ‘_ _ğ‘˜_ in the output nodes of Valid(Â·), where Î¦(Â·) is some arithmetic function, by an output of the form (Î¦( _ğ‘¢_ ) âˆ’ _ğ‘_ 1 ) Ã— Â· Â· Â· Ã— (Î¦( _ğ‘¢_ ) âˆ’ _ğ‘_ _ğ‘˜_ ) .
Recall that in EIFFeL, the honest clients have well-formed inputs
that satisfy Valid(Â·) by definition. Hence, this optimization does not
violate the privacy of honest, which is our security goal.


_Improvement._ Reduces the circuit size |Valid|.
_Cost._ No cost.


**Proof Summary Computation.** In addition to being a linear secret sharing scheme, Shamirâ€™s scheme is also multiplicative: given
the shares of two secrets ( _ğ‘–,ğ‘§_ _ğ‘–_ ) and ( _ğ‘–, ğ‘£_ _ğ‘–_ ), a party can locally compute ( _ğ‘–,ğ‘ _ _ğ‘–_ ) with _ğ‘ _ = _ğ‘§_ - _ğ‘£_ . However, if the original shares correspond
to a polynomial of degree _ğ‘¡_, the new shares represent a polynomial
of degree 2 _ğ‘¡_ . Hence, we do not rely on this property for the multiplication gates of Valid(Â·) as it would support only limited number
of multiplications. However, if _ğ‘š_ _<_ _[ğ‘›]_ [âˆ’] ~~4~~ [1] [, we can still leverage the]

multiplicative property to generate shares of the random digest
_ğœ†_ _ğ‘–_ = _ğ‘“_ _ğ‘–_ ( _ğ‘Ÿ_ ) Â· _ğ‘”_ _ğ‘–_ ( _ğ‘Ÿ_ ) = _â„_ _ğ‘–_ ( _ğ‘Ÿ_ ) locally (instead of using Beaverâ€™s triples).


_Improvement._ Saves a round of communication and reduces the
number of robust reconstructions for _ğœ†_ _ğ‘–_ from three to just one
(details in App. 11.1).
_Cost._ No cost.


**Random Projection** . As shown in Table 1, both communication
and computation grows linearly with the data dimension _ğ‘‘_ . Hence,
we rely on the random projection [ 66 ] technique for reducing the
dimension of the updates. Specifically, we use the fast random
projection using Walsh-Hadamard transforms [4].


_Improvement._ Reduces the data dimension which helps both computation and communication cost.
_Cost._ Empirical evaluation (Sec. 7.2) shows that the efficacy of
Valid(Â·) is still preserved.


**7** **Experimental Evaluation**


**7.1** **Performance Evaluation.**


In this section, we analyze the performance of EIFFeL.


**Configuration.** We run experiments on two Amazon EC2 c5.9large
instances with Intel Xeon Platinum 8000 processors. To emulate
server-client communication, we use two instances in the US East
(Ohio) and US West (Oregon) regions, with a round trip time of
21 ms. We implemented EIFFeL in Python and C++ using NTL library [ 1 ]. We use AES-GCM for encryption, a 56-bit prime field
F and probabilistic quantization [ 47 ]. For key agreement, we use
elliptic curve Diffie-Hellman [ 32 ] over the NIST P-256 curve. Unless otherwise specified, the default settings are _ğ‘‘_ = 1 _ğ¾_, _ğ‘›_ = 100,
_ğ‘š_ = 10% and |Valid(Â·)| â‰ˆ 4 _ğ‘‘_ . We report the mean of 10 runs for each


E FFeL: Ensuring Integrity For Federated Learning CCS â€™22, November 7â€“11, 2022, Los Angeles, CA, USA





















**Figure 5: Computation cost analysis of EIFFeL. The left two plots show the runtime of a single client client in milliseconds as a function of:**
**(left) the number of clients** _ğ‘›_ **and (right) dimensionality of the updates** _ğ‘‘_ **. The right two plots show the runtime of the server as a function of**
**the same variables. The results demonstrate that performance decays quadratically in** _ğ‘›_ **, and linearly in** _ğ‘‘_ **.**
















|100 (MB) 5% malicious 10%    "|5% malicious 10%    "|s clients|Col4|
|---|---|---|---|
|~~50~~<br>~~100~~<br>Numb<br>0<br>20<br>40<br>60<br>80<br><br><br>15%       "<br>~~20%       "~~|15%       "<br>~~20%       "~~|||
|~~50~~<br>~~100~~<br>Numb<br>0<br>20<br>40<br>60<br>80<br><br><br>15%       "<br>~~20%       "~~||||
|~~50~~<br>~~100~~<br>Numb<br>0<br>20<br>40<br>60<br>80<br><br><br>15%       "<br>~~20%       "~~||~~150~~<br>~~200~~<br>~~250~~<br>er of Clients|~~150~~<br>~~200~~<br>~~250~~<br>er of Clients|


|200 (MB)|Col2|Col3|Col4|
|---|---|---|---|
|~~1,000~~<br>~~5,000~~<br>~~10,00~~<br>Data Dimension<br>0<br>50<br>100<br>150<br>||||
|~~1,000~~<br>~~5,000~~<br>~~10,00~~<br>Data Dimension<br>0<br>50<br>100<br>150<br>||||


|100 (MB)|Col2|Server|r|
|---|---|---|---|
|~~50~~<br>~~100~~<br>N<br>0<br>25<br>50<br>75<br>||||
|~~50~~<br>~~100~~<br>N<br>0<br>25<br>50<br>75<br>||||
|~~50~~<br>~~100~~<br>N<br>0<br>25<br>50<br>75<br>||~~150~~<br>mber of|~~200~~<br>~~250~~<br>lients|


|150 180 (MB) Server|Serv|ver|Col4|
|---|---|---|---|
|~~1,000~~<br>~~5,000~~<br>~~10,00~~<br>Data Dimension<br>0<br>30<br>60<br>90<br>120<br>150<br>||||
|~~1,000~~<br>~~5,000~~<br>~~10,00~~<br>Data Dimension<br>0<br>30<br>60<br>90<br>120<br>150<br>||||



**Figure 6: Communication cost analysis of EIFFeL. The left two plots show the amount of communication (in MB) for each client as a function**
**of: (left) the number of clients** _ğ‘›_ **and (right) dimensionality of the updates** _ğ‘‘_ **. The right two plots show the the amount of communication (in**
**MB) for the server as a function of the same variables. The results show communication increases quadratically in** _ğ‘›_ **, and linearly in** _ğ‘‘_ **.**



experiment. The rejection probability ( _ğ‘›ğ‘’ğ‘”ğ‘™_ ( _ğœ…_ )) is dominated by
2Mâˆ’2 / |F | (soundness error of SNIP, Sec. 4.1). M _<_ 4 _ğ‘‘_ _<_ 40 _ğ¾_ in our
evaluation so the failure probability is of the order of _ğ‘‚_ (10 [âˆ’][12] ).


**Computation Costs.** Fig. 5 presents EIFFeLâ€™s runtime. We vary
the number of malicious clients between 5%-20% of the number of

clients. We observe that per-client runtime of EIFFeL is low: it is
1 _._ 3 _ğ‘ _ if _ğ‘š_ = 10%, _ğ‘‘_ = 1 _ğ¾_, and _ğ‘›_ = 100. The runtime scales quadratically in _ğ‘›_ because a client has _ğ‘‚_ ( _ğ‘šğ‘›ğ‘‘_ ) computation complexity (see
Table 1) and _ğ‘š_ is a linear function of _ğ‘›_ . As expected, the runtime
increases linearly with _ğ‘‘_ . A client takes around 11 _ğ‘ _ when _ğ‘‘_ = 10 _ğ¾_,
_ğ‘›_ = 100, and _ğ‘š_ = 10%. The runtime for the server is also low: the
server completes its computation in about 1 _ğ‘ _ for _ğ‘›_ = 100, _ğ‘‘_ = 1 _ğ¾_,
and _ğ‘š_ = 10%. The serverâ€™s runtime also scales quadratically in _ğ‘›_
due to the _ğ‘‚_ ( _ğ‘šğ‘›ğ‘‘_ ) computation complexity (Table 1). The runtime
increases linearly with _ğ‘‘_ .


In Fig. 7, we break down the runtime per round. We observe that:
Round 1 (announcing public information) incurs negligible cost
for both clients and the server; and Round 3 (verify proof) is the
costliest round for both clients and the server where the dominating
cost is verifying the validity of the shares (Sec. 11.2). Note that the
server has no runtime cost for Round 2 since the proof generation
only involves clients.


Table 2 presents our end-to-end performance which contains the
runtimes of a client, the server and the communication latencies.
For instance, the end-to-end runtime for _ğ‘›_ = 100, _ğ‘‘_ = 1 _ğ¾_ and _ğ‘š_ = 10%
is âˆ¼ 2 _._ 4 _ğ‘ _ . We also present the impact of one of our key optimizations â€“ eliminating the verification of the secrets shares of the proof
â€“ which cuts down the costliest step in EIFFeL and improves the
performance by 2 _._ 3 Ã— . Additionally, we compare EIFFeLâ€™s performance with BREA [80], which is a Byzantine-robust secure aggregator. EIFFeL differs from BREA in two key ways: ( 1 ) EIFFeL is a
general framework for per-client update integrity checks whereas



**Figure 7: Computation cost per round in EIFFeL.**

BREA implements the multi-Krum aggregation algorithm [ 15 ] that
considers the entire dataset to determine the malicious updates
(computes all the pairwise distances between the clients and then,
detects the outliers), and ( 2 ) BREA has an additional privacy leakage as it reveals the values of all the pairwise distances between
clients. Nevertheless, we choose BREA as our baseline because, to
the best of our knowledge, this is the only prior work that: ( 1 )
detects and removes malformed updates, and ( 2 ) works in the malicious threat model with ( 3 ) a single server (see Table 3, Sec. 9).
We observe that EIFFeL outperforms BREA and that the improvement increases with _ğ‘›_ . For instance, for _ğ‘›_ = 250, EIFFeL is 18 _._ 5 Ã—
more performant than BREA. This is due to BREAâ€™s complexity
of _ğ‘‚_ ( _ğ‘›_ [3] log [2] _ğ‘›_ log log _ğ‘›_ + _ğ‘šğ‘›ğ‘‘_ ), where the _ğ‘‚_ ( _ğ‘›_ [3] ) factor is due to each
client partaking in the computation of the _ğ‘‚_ ( _ğ‘›_ [2] ) pairwise distances.


**Communication Cost.** Fig. 6 depicts the total data transferred by



**Improvement over**


**# Clients** ( _ğ‘›_ ) **Time** (ms) Unoptimized EIFFeL BREA [80]


50 1,072 2.3Ã— 2.5Ã—

100 2,367 2.3Ã— 5.2Ã—

150 4,326 2.3Ã— 7.8Ã—

200 6,996 2.3Ã— 12.8Ã—

250 10,389 2.3Ã— 18.5Ã—


**Table 2: End-to-end time for a single iteration of EIFFeL with** _ğ‘‘_ = 1000
**and** _ğ‘š_ = 10% **malicious clients, as a function of the number of clients,**
_ğ‘›_ **. We also compare it with a variant of EIFFeL without optimiza-**
**tions, and with BREA [80].**










CCS â€™22, November 7â€“11, 2022, Los Angeles, CA, USA Roy Chowdhury et al.







**(a) MNIST: Sign flip attack with norm**
**ball validation predicate (defense).**


**(e)** **MNIST:** **Min-Max** **attack** **with**
**Zeno++ validation predicate.**



|100|Col2|
|---|---|
|~~1~~<br>40<br>60<br>80<br><br>Test Accuracy||
|~~1~~<br>40<br>60<br>80<br><br>Test Accuracy|~~00~~<br>~~200~~<br>~~300~~<br>~~400~~<br>~~500~~<br>Number of Iterations|


**(b) MNIST: Scaling attack and cosine**
**similarity validation predicate.**

|80<br>Accuracy<br>60<br>40 Test<br>20<br>100|Col2|
|---|---|
|~~100~~<br><br>20<br>40<br>60<br>80<br>Test Accuracy|~~300~~<br>~~500~~<br>~~700~~<br>~~900~~<br>umber of Iterations|



**(f) CIFAR-10: Min-Sum attack with co-**
**sine similarity validation predicate.**



|80<br>Accuracy<br>60<br>40<br>Test<br>20<br>100 200<br>Number|Col2|
|---|---|
|~~100~~<br>~~200~~<br>Number<br>20<br>40<br>60<br>80<br>Test Accuracy|~~300~~<br>~~400~~<br>~~500~~<br> of Iterations|


**(c) FMNIST: Additive noise attack with**
**Zeno++ validation predicate.**


|80<br>Accuracy<br>60<br>40<br>Test<br>20<br>1|Col2|
|---|---|
|~~1~~<br>20<br>40<br>60<br>80<br>Test Accuracy|~~00~~<br>~~200~~<br>~~300~~<br>~~400~~<br>~~500~~<br>Number of Iterations|



|100<br>80<br>Accuracy<br>60<br>40<br>Test<br>20<br>0<br>100 20<br>Numbe|Main task<br>Backdoor task|
|---|---|
|~~100~~<br>~~20~~<br>Numbe<br>0<br>20<br>40<br>60<br>80<br>100<br>Test Accuracy|~~0~~<br>~~300~~<br>~~400~~<br>~~500~~<br> of Iterations|


**(g) EMNIST: Backdoor Attack-1 with**
**norm bound validation predicate.**







**(d) FMNIST: Sign flip attack with norm**
**ball validation predicate.**

|100<br>80<br>Accuracy<br>60<br>40<br>Test<br>20<br>0<br>100|Col2|
|---|---|
|~~100~~<br>0<br>20<br>40<br>60<br>80<br>100<br>Test Accuracy|~~300~~<br>~~500~~<br>~~700~~<br>~~900~~<br>Number of Iterations|



**(h) CIFAR-10: Backdoor Attack-2 with**
**norm bound validation predicate.**



**Figure 8: Accuracy analysis of EIFFeL. Test accuracy is shown as a function of the FL iteration for different datasets and attacks.**



a client and the server. The communication complexity is _ğ‘‚_ ( _ğ‘šğ‘›ğ‘‘_ )
for a single client and for the server. Hence, the total communication increases quadratically with _ğ‘›_ and linearly with _ğ‘‘_, respectively.
We observe that EIFFeL has acceptable communication cost. For
instance, the total data consumed by a client is 132MB for the configuration _ğ‘›_ = 100 _,ğ‘‘_ = 10 _ğ¾,ğ‘š_ = 10% . This is equivalent to streaming
a full-HD video for 26 _ğ‘ _ [ 2 ]. Since most clients partake in FL training
iterations infrequently, this communication is acceptable.


**Note.** Recall, we assume the size of the validation predicate to be
|Valid| = _ğ‘‚_ ( _ğ‘‘_ ) since Valid(Â·) defines a function on the input which is
_ğ‘‘_ -dimensional. This assumption is validated by the state-of-the-art
predicates tested in Sec. 7.2. The above experiments use |Valid| â‰ˆ 4 _ğ‘‘_ .
Hence, the overall complexity (App. 11.2) is dominated by the
_ğ‘‚_ ( _ğ‘šğ‘›ğ‘‘_ ) term and does not depend on the validation predicate.


**7.2** **Integrity Guarantee Evaluation**


In this section, we evaluate EIFFeLâ€™s efficacy in ensuring update
integrity on real-world datasets.
**Datasets.** We evaluate EIFFeL on three image datasets:

- _MNIST_ [ 51 ] is a digit classification dataset of 60 _ğ¾_ training images
and 10 _ğ¾_ test images with ten classes.

- _EMNIST_ [ 27 ] is a writer-annotated handwritten digit classification dataset with âˆ¼ 340 _ğ¾_ training and âˆ¼ 40 _ğ¾_ testing images.

- _FMNIST_ [ 96 ] is identical to MNIST in terms number of classes,
and number of training and test images.

- _CIFAR-10_ [ 49 ] contains RGB images with ten object classes. It
has 50 _ğ¾_ training and 10 _ğ¾_ test images.

**Models.** We test EIFFeL with three classification models:

- _LeNet-5_ [ 50 ] has five layers and 60 _ğ¾_ parameters, and is used to
experiment on MNIST and EMNIST.

- For FMNIST, we use a five-layer convolutional network with 70 _ğ¾_
parameters and a similar architecture as LeNet-5.

- We use _ResNet-20_ [ 40 ] with 20 layers and 273 _ğ¾_ parameters for
CIFAR-10.



**Validation Predicates.** To demonstrate the flexibility of EIFFeL,
we evaluate four validations predicates, which represent the current
_state-of-the-art_ defenses against data poisoning, as follows:

- _Norm Bound_ [ 85 ]. This method checks whether the _â„“_ 2 -norm of
a client update is bounded: Valid( _ğ‘¢_ ) = I[âˆ¥ _ğ‘¢_ âˆ¥ 2 _< ğœŒ_ ] where I[Â·] is
the indicator function and the threshold _ğœŒ_ is computed from the
public dataset D _ğ‘ƒ_ .

- _Norm Ball_ [ 83 ]. This method checks whether a client update is
within a spherical radius from _ğ‘£_ which is the gradient update computed from the clean public dataset D _ğ‘ƒ_ : Valid( _ğ‘¢_ ) = Iï¿½âˆ¥ _ğ‘¢_ âˆ’ _ğ‘£_ âˆ¥ 2 â‰¤ _ğœŒ_ ï¿½

where radius _ğœŒ_ is also computed from D _ğ‘ƒ_ .

- _Zeno++_ [ 91 ] compares the client update with a loss gradient _ğ‘£_ that
is computed on the public dataset D _ğ‘ƒ_ : Valid( _ğ‘¢_ ) = I[ _ğ›¾_ âŸ¨ _ğ‘£,ğ‘¢_ âŸ©âˆ’ _ğœŒ_ || _ğ‘¢_ || 2
â‰¥âˆ’ _ğ›¾ğœ–_ ] where _ğ›¾_, _ğœŒ_ and _ğœ–_ are threshold parameters also computed
from D _ğ‘ƒ_ and _ğ‘¢_ is _â„“_ 2 -normalized to have the same norm as _ğ‘£_ .

- _Cosine Similarity_ [ 5, 24 ]. This method compares the cosine similarity between the client update _ğ‘¢_ and the global model update of
the last iteration _ğ‘¢_ [â€²] : Valid( _ğ‘¢_ ) = Iï¿½ âˆ¥ _ğ‘¢_ âŸ¨âˆ¥ _ğ‘¢_ 2 _,_ âˆ¥ _ğ‘¢ğ‘¢_ [â€²] âŸ© ~~[â€²]~~ âˆ¥ 2 _[<][ ğœŒ]_ ï¿½ where _ğœŒ_ is computed from D _ğ‘ƒ_ and _ğ‘¢_ is _â„“_ 2 -normalized to match norm of _ğ‘¢_ [â€²] .
**Poisoning Attacks.** To test the efficacy of EIFFeLâ€™s implementations of the four validation predicates introduced above, we test it
against seven poisoning attacks:

- _Sign Flip Attack_ [ 31 ]. In this attack, the malicious clients flip the
sign of their local update: Ë† _ğ‘¢_ = âˆ’ _ğ‘_  - _ğ‘¢,ğ‘_ âˆˆ R + .

- _Scaling Attack_ [ 10 ] scales a local update to increase its influence
on the global update: Ë† _ğ‘¢_ = _ğ‘_  - _ğ‘¢,ğ‘_ âˆˆ R + .

- _Additive Noise Attack_ [ 53 ] adds Gaussian noise to the local update:

_ğ‘¢_ Ë† = _ğ‘¢_ + _ğœ‚,ğœ‚_ âˆ¼N ( _ğœ, ğœ‡_ ) .

- _Min-Max Attack_ [ 77 ] sets all the malicious updates to be: argmax _ğ›¾_



max _ğ‘–_ âˆˆ[ _ğ‘›_ ] || _ğ‘¢_ Ë† âˆ’ _ğ‘¢_ _ğ‘–_ || 2 â‰¤ max _ğ‘–,ğ‘—_ âˆˆ[ _ğ‘›_ ] || _ğ‘¢_ _ğ‘–_ âˆ’ _ğ‘¢_ _ğ‘—_ || 2 ; Ë† _ğ‘¢_ = ~~_ğ‘›_~~ [1] ï¿½ _ğ‘›ğ‘–_ =1 _[ğ‘¢]_ _[ğ‘–]_ [+] _[ ğ›¾]_ [Â·] _[ ğ‘¢]_ _[ğ‘]_ [,]

where _ğ‘¢_ _[ğ‘]_ is a dataset optimized perturbation vector. Here, the
adversary is assumed to have access to the benign (well-formed)
updates of _all_ clients. This attack finds the malicious gradient
whose maximum distance from a benign gradient is less than the
maximum distance between any two benign gradient.


E FFeL: Ensuring Integrity For Federated Learning CCS â€™22, November 7â€“11, 2022, Los Angeles, CA, USA




- _Min-Sum Attack_ [ 77 ] sets all the malicious updates to be: argmax _ğ›¾_
ï¿½ _ğ‘–_ âˆˆ[ _ğ‘›_ ] [||] _[ğ‘¢]_ [ Ë†] [âˆ’] _[ğ‘¢]_ _ğ‘–_ [||] 2 [â‰¤] [max] _ğ‘–_ âˆˆ[ _ğ‘›_ ] ï¿½ _ğ‘—_ âˆˆ[ _ğ‘›_ ] [||] _[ğ‘¢]_ _ğ‘–_ [âˆ’] _[ğ‘¢]_ _ğ‘—_ [||] 2 [; Ë†] _[ğ‘¢]_ [=] ~~_ğ‘›_~~ [1] ï¿½ _ğ‘›ğ‘–_ =1 _[ğ‘¢]_ _[ğ‘–]_ [+] _[ ğ›¾]_ [Â·] _[ ğ‘¢]_ _[ğ‘]_ [,]

where _ğ‘¢_ _[ğ‘]_ is a dataset optimized perturbation vector. Here, the
adversary is assumed to have access to the benign updates of _all_
clients. This attack finds the malicious gradient such that the sum
of its distances from all the other gradients is less than the sum
of distances of any benign gradient from other benign gradients.

- _Backdoor Attack-1_ [85] classifies the digit seven as the digit one
for EMNIST.

- _Backdoor Attack-2_ [ 5 ] classifies images of green cars as birds for
CIFAR-10.


**Configuration.** We use the same configuration as before. We implement the image-classification models in PyTorch. We randomly
select 10K samples from each training set as the public dataset D _ğ‘ƒ_
and train on the remaining samples. EMNIST is collected from 3383
clients with âˆ¼ 100 images per client. For all other datasets, the
training set is divided into 5K subsets to create the local dataset
for each client. For each training iteration, we sample the required
number of data subsets out of these 5K subsets.


**Results.** Fig. 8 shows the accuracy of different image-classification
models in EIFFeL. We set _ğ‘›_ = 100 and _ğ‘š_ = 10%, and use random
projection to project the updates to a dimension _ğ‘‘_ of 1K (MNIST,
EMNIST), 5K (FMNIST), or 10K (CIFAR-10). For the two backdoor
attacks, we consider _ğ‘š_ = 5%. Our experiment assesses how the
random projection affects the efficacy of the integrity checks. We
observe that for MNIST (Figs. 8a, 8b and 8e), EMNIST (Fig. 8g) and
FMNIST (Fig. 8c and 8d), EIFFeL achieves performance comparable
to a baseline that applies the defense (validation predicate) on the
plaintext. In most cases, the defenses retain their efficacy even
after random projection. This is because they rely on computing
inner products and norms of the update; these operations preserve
their relative values after the projection with high probability [ 66 ].

âˆ¼
We observe a drop in accuracy ( 7%) on CIFAR-10 (Figs. 8f and
8h) as updates for ResNet-20 with 273K parameters are projected
to 10K. The end-to-end per-iteration time ( _ğ‘š_ = 10% ) for MNIST,
EMNIST, FMNIST, and CIFAR-10 is 2 _._ 4 _ğ‘ _ (Table 2), 2 _._ 4 _ğ‘ _, 10 _._ 7 _ğ‘ _, and
20 _._ 5 _ğ‘ _, respectively. The associated communication costs for the
client are 13 _._ 3MB, 13 _._ 3MB, 65 _._ 8MB, and 132MB (Fig. 6). Additional
evaluation results are presented in Fig. 9 (App. 11.6).


**8** **Discussion**


In this section, we discuss possible avenues for future research
(additional discussion in App. 11.7).



**Handling Higher Fraction of Malicious Clients.** For âŒŠ _[ğ‘›]_ [âˆ’] ~~3~~ [1] [âŒ‹] _[<][ ğ‘š]_

_<_ âŒŠ _[ğ‘›]_ [âˆ’] ~~2~~ [1] [âŒ‹] [(honest majority), the current implementation of][ EIFFeL][ can]

detect but not remove malformed inputs (Gaoâ€™s decoding algorithm
returns âŠ¥ if _ğ‘š_ _>_ âŒŠ _[ğ‘›]_ [âˆ’] ~~3~~ [1] [âŒ‹] [). Robust reconstruction in this case could be]

done via Guruswami-Sudan list decoder [ 59 ]. We do not do so in
EIFFeL because the reconstruction might fail sometimes.


**Handling Client Dropouts.** In practice, clients might have only
sporadic access to connectivity and so, the protocol must be robust
to clients dropping out. EIFFeL can already accommodate malicious
client dropping out â€“ it is straightforward to extend this for the
case of honest clients as well.



**Identifying All Malicious Clients.** Currently, EIFFeL identifies
a partial list of malicious clients. To detect all malicious clients,
one can use: ( 1 ) PVSS to identify all clients who have submitted
at least one invalid share, and ( 2 ) decoding algorithms such as
Berlekamp-Welch [ 13 ] that can detect the location of the errors
from the reconstruction. We do not use them in EIFFeL as they have
higher computation cost.


**Reducing Clientâ€™s Computation.** Currently, verifying the validity of the secret shares is the dominant cost for clients. This task
can be offloaded to the server S by using a publicly verifiable secret
sharing scheme (PVSS) [ 73, 82, 86 ] where the validity of a secret
share can be verified by any party. However, typically PVSS employs public key cryptography (which is costlier than symmetric
cryptography) which might increase the end-to-end running time.


**Additional Defense Strategies.** EIFFeL supports any defense strategy that can be expressed as a per-update anomaly detection mechanism (captured via the public validation predicate Valid(Â·) ). A recent
line of work [ 43, 52, 69, 71, 87, 89 ] proposes a complimentary style
of defense which involves inspecting the final aggregate and the
resulting model. For instance, Sparsefed [ 69 ] is a state-of-the-art
backdoor defense where the server selects the top _ğ‘˜_ dimensions
of the final aggregate and updates the model only along those
dimensions (others are set to zero). CRFL [ 89 ] provides certified
robustness against backdoor attacks by clipping and perturbing the
final aggregate and performing parameter smoothing on the global
model during testing. Jia et al. [ 43 ] propose an ensemble learning
mechanism where the server learns multiple global models on randomly selected subset of clients and takes majority vote among
the global models for test-time prediction. Such defenses can be
immediately integrated with EIFFeL since the server has access to
the final aggregate and the updated global model in the clear.


**Towards poly-logarithmic complexity.** Currently, dominant term
in the complexity is _ğ‘‚_ ( _ğ‘šğ‘›ğ‘‘_ ) which results in a _ğ‘‚_ ( _ğ‘›_ [2] ) dependence
on _ğ‘›_ (since we consider _ğ‘š_ is a fraction of _ğ‘›_ ). This can be reduced to
_ğ‘‚_ ( _ğ‘›_ log [2] _ğ‘›ğ‘‘_ ) by using the techniques from [ 9 ]. A detailed discussion
is presented in App. 11.7.


**9** **Related Work**


**Table 3: Comparison of EIFFeL with Related Work**


Work Malicious Single Removes Arbritrary
Threat Model Server Malformed Inputs Integrity Checks


He et.al [41] Ã— Ã— Ã— Ã—
FLGuard [67] Ã— Ã— Ã— Ã—
RoFL [23] Ã— âœ“ Ã— Ã—
BREA* [80] âœ“ âœ“ âœ“ Ã—
EIFFeL(Our) âœ“ âœ“ âœ“ âœ“

*Has additional privacy leakage


**Secure Aggregation.** Prior work has addressed the problem of
(non-Byzantine) secure aggregation in FL [ 3, 9, 17, 81 ]. A popular
approach is to use pairwise random masking to protect the local updates [ 3, 17 ]. Advancements have been made in the communication
overhead [18, 48, 81].


**Robust Machine Learning.** A large number of studies have explored methods to make machine learners robust to Byzantine


CCS â€™22, November 7â€“11, 2022, Los Angeles, CA, USA Roy Chowdhury et al.



failures [ 5, 10, 45 ]. Many of these robust machine-learning methods require the learned to have full access to the training data or
to fully control the training process [ 29, 39, 56, 79, 83, 88 ] which
is infeasible in FL. Another line of work has focused on the de
velopment of estimators that are inherently robust to Byzantine
errors [ 15, 25, 68, 70, 94 ]. In our work, we target a set of methods
that provides robustness by checking per-client updates [ 15, 36, 78 ].


**Verifying Data Integrity in Secure Aggregation.** Table 3 compares EIFFeL with prior work. There are three key differences between RoFL [ 23 ] and EIFFeL: ( 1 ) RoFL is designed only for range
checks with _â„“_ 2 or _â„“_ âˆ norms. Specifically, RoFL uses Bulletproofs
which is especially performant for range proofs (range proofs can
be aggregated where one can prove that _ğ‘›_ commitments lie within
a given range by providing only an additive _ğ‘‚_ ( _ğ‘™ğ‘œğ‘”_ ( _ğ‘›_ )) group elements over the length of a single proof). RoFLâ€™s performance is
primarily based on this aspect of Bulletproof and all of its optimizations work only for range proofs. As such RoFL cannot support any
other checks with the same performance as currently reported in
the paper. By contrast, EIFFeL is a general framework that supports
arbitrary validation predicates with good performance. ( 2 ) RoFL
is susceptible to DoS attacks because it _only_ detects malformed
updates and aborts if it finds one. Specifically, the recovery of the
final aggregate in RoFL requires a step of nonce cancellation that
involves all the inputs by design. Hence, even if one of the input is
invalid, the final aggregate will be ill-formed. By contrast, EIFFeL is
a SAVI protocol that detects and removes malformed updates in every round. ( 3 ) RoFL assumes an honest-but-curious server, whereas
EIFFeL considers a malicious threat model. BREA [ 80 ] also removes
outlying updates but, unlike EIFFeL, it leaks pairwise distances
between inputs. Alternative solutions [ 41, 67 ] for distance-based
Byzantine-robust aggregation uses two non-colluding servers in
the semi-honest threat model, which is incompatible with FL.


**10** **Conclusion**


Practical FL settings need to ensure both the privacy and integrity
of model updates provided by the clients. In this paper, we have
formalized these goals in a new protocol, SAVI, that securely aggregates _only_ well-formed inputs ( _i.e._, updates). To demonstrate
the feasibility of SAVI, we have proposed EIFFeL: a system that
efficiently instantiates a SAVI protocol.


**References**


[[1] https://libntl.org/.](https://libntl.org/)

[2] Youtube system requirements. [https://support.google.com/youtube/answer/](https://support.google.com/youtube/answer/78358?hl=en)
[78358?hl=en.](https://support.google.com/youtube/answer/78358?hl=en)

[3] Gergely Ãcs and Claude Castelluccia. I have a dream! differentially private smart
metering. In _Proceedings of the 13th International Conference on Information_
_Hiding_, IHâ€™11, page 118â€“132, Berlin, Heidelberg, 2011. Springer-Verlag.

[4] Nir Ailon and Bernard Chazelle. Approximate nearest neighbors and the fast
johnson-lindenstrauss transform. In _Proceedings of the Thirty-Eighth Annual_
_ACM Symposium on Theory of Computing_, STOC â€™06, page 557â€“563, New York,
NY, USA, 2006. Association for Computing Machinery.

[5] Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah Estrin, and Vitaly
Shmatikov. How to backdoor federated learning. In _arXiv:1807.00459_, 2018.

[6] Raef Bassily, Albert Cheu, Shay Moran, Aleksandar Nikolov, Jonathan Ullman,
and Zhiwei Steven Wu. Private query release assisted by public data. In _ICML_,
2020.

[7] Donald Beaver. Efficient multiparty protocols using circuit randomization. In
Joan Feigenbaum, editor, _Advances in Cryptology â€” CRYPTO â€™91_, pages 420â€“432,
Berlin, Heidelberg, 1992. Springer Berlin Heidelberg.




[8] Amos Beimel, Aleksandra Korolova, Kobbi Nissim, Or Sheffet, and Uri Stemmer.
The power of synergy in differential privacy: Combining a small curator with
local randomizers. In _ITC_, 2020.

[9] James Henry Bell, Kallista A. Bonawitz, AdriÃ  GascÃ³n, TancrÃ¨de Lepoint, and Mariana Raykova. Secure single-server aggregation with (poly)logarithmic overhead.
In _Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communica-_
_tions Security_, CCS â€™20, page 1253â€“1269, New York, NY, USA, 2020. Association
for Computing Machinery.

[10] Arjun Nitin Bhagoji, Supriyo Chakraborty, Prateek Mittal, and Seraphin Calo.
Analyzing federated learning through an adversarial lens. In _Proceedings of the_
_International Conference on Machine Learning_, pages 634â€“643, 2019.

[11] Abhishek Bhowmick, John C. Duchi, Julien Freudiger, Gaurav Kapoor, and
Ryan M. Rogers. Protection against reconstruction and its applications in private
federated learning. _ArXiv_, abs/1812.00984, 2018.

[12] Battista Biggio, Blaine Nelson, and Pavel Laskov. Poisoning attacks against support vector machines. In _Proceedings of the International Coference on International_
_Conference on Machine Learning_, pages 1467â€“1474, 2012.

[13] Richard E. Blahut. Theory and practice of error control codes. 1983.

[14] P. Blanchard, E. M. E. Mhamdi, R. Guerraoui, and J. Stainer. Byzantine-tolerant
machine learning. In _arXiv:1703.02757_, 2017.

[15] Peva Blanchard, El Mahdi El Mhamdi, Rachid Guerraoui, and Julien Stainer.
Machine learning with adversaries: Byzantine tolerant gradient descent. In
_Advances in Neural Information Processing Systems_, pages 118â€“128, 2017.

[16] Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex
Ingerman, Vladimir Ivanov, Chloe Kiddon, Jakub KoneÄnÃ½, Stefano Mazzocchi,
H. Brendan McMahan, Timon Van Overveldt, David Petrou, Daniel Ramage, and
Jason Roselander. Towards federated learning at scale: System design, 2019.

[17] Keith Bonawitz, Vladimir Ivanov, Ben Kreuter, Antonio Marcedone, H. Brendan
McMahan, Sarvar Patel, Daniel Ramage, Aaron Segal, and Karn Seth. Practical
secure aggregation for privacy-preserving machine learning. In _Proceedings of_
_the ACM SIGSAC Conference on Computer and Communications Security_, pages
1175â€“1191, 2017.

[18] Keith Bonawitz, Fariborz Salehi, Jakub KonecnÃ½, H. Brendan McMahan, and
Marco Gruteser. Federated learning with autotuned communication-efficient
secure aggregation. _2019 53rd Asilomar Conference on Signals, Systems, and_
_Computers_, pages 1222â€“1226, 2019.

[19] Dan Boneh, Elette Boyle, Henry Corrigan-Gibbs, Niv Gilboa, and Yuval Ishai.
Zero-knowledge proofs on secret-shared data via fully linear pcps. In _CRYPTO_,
2019.

[20] Dan Boneh, Rosario Gennaro, Steven Goldfeder, Aayush Jain, Sam Kim, Peter
M. R. Rasmussen, and Amit Sahai. Threshold cryptosystems from threshold fully
homomorphic encryption. In _Advances in Cryptology â€“ CRYPTO 2018: 38th Annual_
_International Cryptology Conference, Santa Barbara, CA, USA, August 19â€“23, 2018,_
_Proceedings, Part I_, page 565â€“596, Berlin, Heidelberg, 2018. Springer-Verlag.

[21] Gabriel Bracha and Sam Toueg. Asynchronous consensus and broadcast protocols.
_J. ACM_, 32(4):824â€“840, oct 1985.

[22] Zvika Brakerski, Craig Gentry, and Vinod Vaikuntanathan. (leveled) fully homomorphic encryption without bootstrapping. In _Proceedings of the 3rd Innovations_
_in Theoretical Computer Science Conference_, ITCS â€™12, page 309â€“325, New York,
NY, USA, 2012. Association for Computing Machinery.

[23] Lukas Burkhalter, Hidde Lycklama, Alexander Viand, Nicolas KÃ¼chler, and Anwar Hithnawi. Rofl: Attestable robustness for secure federated learning. In
_arXiv:2107.03311_, 2021.

[24] Xiaoyu Cao, Minghong Fang, Jia Liu, and Neil Zhenqiang Gong. Fltrust:
Byzantine-robust federated learning via trust bootstrapping. 2021.

[25] Lingjiao Chen, Hongyi Wang, Zachary Charles, and Dimitris Papailiopoulos.
Draco: Byzantine-resilient distributed training via redundant gradients. In _Pro-_
_ceedings of the International Conference on Machine Learning_, 2018.

[26] Xinyun Chen, Chang Liu, Bo Li, Kimberly Lu, and Dawn Song. Targeted backdoor
attacks on deep learning systems using data poisoning. In _arXiv:1712.05526_, 2017.

[27] Gregory Cohen, Saeed Afshar, Jonathan Tapson, and AndrÃ© van Schaik. Emnist:
Extending mnist to handwritten letters. In _2017 International Joint Conference on_
_Neural Networks (IJCNN)_, pages 2921â€“2926, 2017.

[28] Henry Corrigan-Gibbs and Dan Boneh. Prio: Private, robust, and scalable computation of aggregate statistics. In _Proceedings of the USENIX Symposium on_
_Networked Systems Design and Implementation_, 2017.

[29] Gabriela F. Cretu, Angelos Stavrou, Michael E. Locasto, Salvatore J. Stolfo, and
Angelos D. Keromytis. Casting out demons: Sanitizing training data for anomaly
sensors. In _IEEE Symposium on Security and Privacy (SP)_, pages 81â€“95, 2008.

[30] Scott A. Crosby and Dan S. Wallach. Efficient data structures for tamper-evident
logging. In _Proceedings of the 18th Conference on USENIX Security Symposium_,
SSYMâ€™09, page 317â€“334, USA, 2009. USENIX Association.

[31] Georgios Damaskinos, El Mahdi El Mhamdi, Rachid Guerraoui, Rhicheek Patra,
and Mahsa Taziki. Asynchronous byzantine machine learning (the case of sgd).
In _ICML_, 2018.

[32] W. Diffie and M. Hellman. New directions in cryptography. _IEEE Transactions on_
_Information Theory_, 22(6):644â€“654, 1976.


E FFeL: Ensuring Integrity For Federated Learning CCS â€™22, November 7â€“11, 2022, Los Angeles, CA, USA




[33] El Mahdi El Mhamdi, Rachid Guerraoui, and SÃ©bastien Rouault. The hidden
vulnerability of distributed learning in Byzantium. In Jennifer Dy and Andreas
Krause, editors, _Proceedings of the 35th International Conference on Machine Learn-_
_ing_, volume 80 of _Proceedings of Machine Learning Research_, pages 3521â€“3530.
PMLR, 10â€“15 Jul 2018.

[34] Minghong Fang, Xiaoyu Cao, Jinyuan Jia, and Neil Zhenqiang Gong. Local model
poisoning attacks to byzantine-robust federated learning. In _USENIX Security_
_Symposium_, 2020.

[35] Paul Feldman. A practical scheme for non-interactive verifiable secret sharing.
In _28th Annual Symposium on Foundations of Computer Science (sfcs 1987)_, pages
427â€“438, 1987.

[36] Clement Fung, Chris J.M. Yoon, and Ivan Beschastnikh. Mitigating sybils in
federated learning poisoning. In _arXiv:1808.04866_, 2018.

[37] Shuhong Gao. _A New Algorithm for Decoding Reed-Solomon Codes_, pages 55â€“68.
Springer US, Boston, MA, 2003.

[38] Joachim von zur Gathen and Jrgen Gerhard. _Modern Computer Algebra_ . Cambridge University Press, USA, 3rd edition, 2013.

[39] Tianyu Gu, Brendan Dolan-Gavitt, and Siddharth Garg. Badnets: Identifying
vulnerabilities in the machine learning model supply chain. In _arXiv:1708.06733_,
2017.

[40] Kaiming He, X. Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning
for image recognition. _2016 IEEE Conference on Computer Vision and Pattern_
_Recognition (CVPR)_, pages 770â€“778, 2016.

[41] Lie He, Sai Praneeth Karimireddy, and Martin Jaggi. Secure byzantine-robust
machine learning, 2020.

[42] Aayush Jain, Peter M. R. Rasmussen, and Amit Sahai. Threshold fully homomorphic encryption. Cryptology ePrint Archive, Report 2017/257, 2017.
[https://ia.cr/2017/257.](https://ia.cr/2017/257)

[43] Jinyuan Jia, Xiaoyu Cao, and Neil Zhenqiang Gong. Intrinsic certified robustness
of bagging against data poisoning attacks. In _AAAI_, 2021.

[44] Peter Kairouz, Ziyu Liu, and Thomas Steinke. The distributed discrete gaussian
mechanism for federated learning with secure aggregation. _ArXiv_, abs/2102.06387,
2021.

[45] Peter Kairouz, H. Brendan McMahan, Brendan Avent, Aurelien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode,
Rachel Cummings, Rafael G.L. Dâ€™Oliveira, Hubert Eichner, Salim El Rouayheb,
David Evans, Josh Gardner, Zachary Garrett, Adria Gascon, Badih Ghazi, Phillip B.
Gibbons, Marco Gruteser, Zaid Harchaoui, Chaoyang He, Lie He, Zhouyuan Huo,
Ben Hutchinson, Justin Hsu, Martin Jaggi, Tara Javidi, Gauri Joshi, Mikhail Khodak, Jakub Konecny, Aleksandra Korolova, Farinaz Koushanfar, Sanmi Koyejo,
Tancrede Lepoint, Yang Liu, Prateek Mittal, Mehryar Mohri, Richard Nock, Ayfer
Ozgur, Rasmus Pagh, Hang Qi, Daniel Ramage, Ramesh Raskar, Mariana Raykova,
Dawn Song, Weikang Song, Sebastian U. Stich, Ziteng Sun, Ananda Theertha
Suresh, Florian Tramer, Praneeth Vepakomma, Jianyu Wang, Li Xiong, Zheng Xu,
Qiang Yang, Felix X. Yu, Han Yu, and Sen Zhao. Advances and open problems in
federated learning. In _arXiv:1912.04977_, 2019.

[46] Jonathan Katz and Yehuda Lindell. _Introduction to Modern Cryptography, Second_
_Edition_ . Chapman & Hall/CRC, 2nd edition, 2014.

[47] Jakub KoneÄnÃ½, H. Brendan McMahan, Felix X. Yu, Peter RichtÃ¡rik,
Ananda Theertha Suresh, and Dave Bacon. Federated learning: Strategies for
improving communication efficiency. _CoRR_, abs/1610.05492, 2016.

[48] Jakub KonecnÃ½, H. Brendan McMahan, Felix X. Yu, Peter RichtÃ¡rik,
Ananda Theertha Suresh, and Dave Bacon. Federated learning: Strategies for
improving communication efficiency. _ArXiv_, abs/1610.05492, 2016.

[49] Alex Krizhevsky. The cifar-10 dataset.

[50] Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied
to document recognition. _Proceedings of the IEEE_, 86(11):2278â€“2324, 1998.

[51] Yann LeCun, Corinna Cortes, and Christopher J.C. Burges. The mnist database
of handwritten digits.

[52] Alexander Levine and Soheil Feizi. Provable adversarial robustness for fractional
lp threat models. In Gustau Camps-Valls, Francisco J. R. Ruiz, and Isabel Valera,
editors, _International Conference on Artificial Intelligence and Statistics, AISTATS_
_2022, 28-30 March 2022, Virtual Event_, volume 151 of _Proceedings of Machine_
_Learning Research_, pages 9908â€“9942. PMLR, 2022.

[53] Liping Li, Wei Xu, Tianyi Chen, Georgios Giannakis, and Qing Ling. Rsa:
Byzantine-robust stochastic aggregation methods for distributed learning from
heterogeneous datasets. _Proceedings of the AAAI Conference on Artificial Intelli-_
_gence_, 33:1544â€“1551, 07 2019.

[54] Suyi Li, Yong Cheng, Wei Wang, Yang Liu, and Tianjian Chen. Learning to detect
malicious clients for robust federated learning. _CoRR_, abs/2002.00211, 2020.

[55] Shu Lin and Daniel J. Costello. _Error control coding: fundamentals and applications_ .
Pearson/Prentice Hall, Upper Saddle River, NJ, 2004.

[56] Kang Liu, Brendan Dolan-Gavitt, and Siddharth Garg. Fine-pruning: Defending
against backdooring attacks on deep neural networks. pages 273â€“294, 2018.

[57] Terrance Liu, Giuseppe Vietri, Thomas Steinke, Jonathan Ullman, and Zhiwei Steven Wu. Leveraging public data for practical private query release, 2021.

[58] [Wolfram Mathworld. Lagrange interpolating polynomial. https://mathworld.](https://mathworld.wolfram.com/LagrangeInterpolatingPolynomial.html)
[wolfram.com/LagrangeInterpolatingPolynomial.html.](https://mathworld.wolfram.com/LagrangeInterpolatingPolynomial.html)




[59] R. J. McEliece. The guruswamiâ€“sudan decoding algorithm for reedâ€“solomon
codes, 2003.

[60] Brendan McMahan and Daniel Ramage. Federated learning: Collaborative machine learning without centralized training data, 2017.

[61] H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and
Blaise AgÃ¼era y Arcas. Communication-efficient learning of deep networks
from decentralized data. In _Proceedings of the International Conference on Artifi-_
_cial Intelligence and Statistics_, 2017.

[62] Shike Mei and Xiaojin Zhu. Using machine teaching to identify optimal trainingset attacks on machine learners. In _Proceedings of the AAAI Conference on Artificial_
_Intelligence_, pages 2871â€“2877, 2015.

[63] Luca Melis, Congzheng Song, Emiliano De Cristofaro, and Vitaly Shmatikov.
Exploiting unintended feature leakage in collaborative learning. In _2019 IEEE_
_Symposium on Security and Privacy (SP)_, pages 691â€“706, 2019.

[64] Mohammad Naseri, Jamie Hayes, and Emiliano De Cristofaro. Local and central
differential privacy for robustness and privacy in federated learning, 2021.

[65] Milad Nasr, Reza Shokri, and Amir Houmansadr. Comprehensive privacy analysis of deep learning: Passive and active white-box inference attacks against
centralized and federated learning. _2019 IEEE Symposium on Security and Privacy_
_(SP)_, May 2019.

[66] Jelani Nelson. Sketching algorithms.

[67] Thien Duc Nguyen, Phillip Rieger, Hossein Yalame, Helen MÃ¶llering, Hossein
Fereidooni, Samuel Marchal, Markus Miettinen, Azalia Mirhoseini, Ahmad-Reza
Sadeghi, Thomas Schneider, and Shaza Zeitouni. Flguard: Secure and private
federated learning, 2021.

[68] Xudong Pan, Mi Zhang, Duocai Wu, Qifan Xiao, Shouling Ji, and Zhemin Yang.
Justinianâ€™s GAAvernor: Robust distributed learning with gradient aggregation
agent. In _USENIX Security_, pages 1641â€“1658, 2020.

[69] Ashwinee Panda, Saeed Mahloujifar, Arjun Nitin Bhagoji, Supriyo Chakraborty,
and Prateek Mittal. Sparsefed: Mitigating model poisoning attacks in federated
learning with sparsification. In Gustau Camps-Valls, Francisco J. R. Ruiz, and
Isabel Valera, editors, _Proceedings of The 25th International Conference on Artificial_
_Intelligence and Statistics_, volume 151 of _Proceedings of Machine Learning Research_,
pages 7587â€“7624. PMLR, 28â€“30 Mar 2022.

[70] Shashank Rajput, Hongyi Wang, Zachary Charles, and Dimitris Papailiopoulos.
Detox: A redundancy-based framework for faster and more robust gradient
aggregation. 2019.

[71] Elan Rosenfeld, Ezra Winston, Pradeep Ravikumar, and J. Zico Kolter. Certified
robustness to label-flipping attacks via randomized smoothing. In _ICML_, 2020.

[72] Edo Roth, Daniel Noble, Brett Hemenway Falk, and Andreas Haeberlen. Honeycrisp: Large-scale differentially private aggregation without a trusted core. In
_Proceedings of the 27th ACM Symposium on Operating Systems Principles_, SOSP â€™19,
page 196â€“210, New York, NY, USA, 2019. Association for Computing Machinery.

[73] Berry Schoenmakers. A simple publicly verifiable secret sharing scheme and its
application to electronic voting. In _In CRYPTO_, pages 148â€“164. Springer-Verlag,
1999.

[74] J. T. Schwartz. Fast probabilistic algorithms for verification of polynomial identities. _J. ACM_, 27(4):701â€“717, October 1980.

[75] Adi Shamir. How to share a secret. _Commun. ACM_, 22(11):612â€“613, November

1979.

[76] Virat Shejwalkar and Amir Houmansadr. Manipulating the byzantine: Optimizing
model poisoning attacks and defenses for federated learning. In _NDSS_, 2021.

[77] Virat Shejwalkar and Amir Houmansadr. Manipulating the byzantine: Optimizing
model poisoning attacks and defenses for federated learning. In _NDSS_, 2021.

[78] Shiqi Shen, Shruti Tople, and Prateek Saxena. Auror: Defending against poisoning
attacks in collaborative deep learning systems. In _ACM ACSAC_, pages 508â€“519,
2016.

[79] Yanyao Shen and Sujay Sanghavi. Learning with bad training data via iterative
trimmed loss minimization. In _International Conference on Machine Learning_
_(ICML)_, pages 5739â€“5748, 2019.

[80] Jinhyun So, Basak Guler, and A. Salman Avestimehr. Byzantine-resilient secure
federated learning. _IEEE Journal in Selected Areas in Communications: Machine_
_Learning in Communications and Networks_, 2020.

[81] Jinhyun So, Basak Guler, and A. Salman Avestimehr. Turbo-aggregate: Breaking
the quadratic aggregation barrier in secure federated learning, 2021.

[82] Markus Stadler. Publicly verifiable secret sharing. pages 190â€“199. Springer-Verlag,
1996.

[83] Jacob Steinhardt, Pang Wei W. Koh, and Percy S. Liang. Certified defenses for
data poisoning attacks. In _Advances in Neural Information Processing Systems_
_(NeurIPS)_, pages 3517â€“3529, 2017.

[84] Ziteng Sun, Peter Kairouz, Ananda Theertha Suresh, and H. Brendan McMahan.
Can you really backdoor federated learning? In _arXiv:1911.07963_, 2019.

[85] Ziteng Sun, Peter Kairouz, Ananda Theertha Suresh, and H. Brendan McMahan.
Can you really backdoor federated learning? _ArXiv_, abs/1911.07963, 2019.

[86] Chunming Tang, Dingyi Pei, and Zhuojun Liu Yong He. Non-interactive and
information-theoretic secure publicly verifiable secret sharing.

[87] Binghui Wang, Xiaoyu Cao, Jinyuan jia, and Neil Zhenqiang Gong. On certifying
robustness against backdoor attacks via randomized smoothing, 2020.


CCS â€™22, November 7â€“11, 2022, Los Angeles, CA, USA Roy Chowdhury et al.


[88] Bolun Wang, Yuanshun Yao, Shawn Shan, Huiying Li, Bimal Viswanath, Haitao
Zheng, and Ben Y. Zhao. Neural cleanse: Identifying and mitigating backdoor
attacks in neural networks. In _IEEE Symposium on Security and Privacy (SP)_,
pages 707â€“723, 2019.

[89] Chulin Xie, Minghao Chen, Pin-Yu Chen, and Bo Li. Crfl: Certifiably robust
federated learning against backdoor attacks. In Marina Meila and Tong Zhang,
editors, _Proceedings of the 38th International Conference on Machine Learning_,
volume 139 of _Proceedings of Machine Learning Research_, pages 11372â€“11382.
PMLR, 18â€“24 Jul 2021.

[90] Chulin Xie, Keli Huang, Pin-Yu Chen, and Bo Li. Dba: Distributed backdoor
attacks against federated learning. In _ICLR_, 2020.

[91] Cong Xie. Zeno++: robust asynchronous SGD with arbitrary number of byzantine
workers. _CoRR_, abs/1903.07020, 2019.

[92] Cong Xie, Oluwasanmi Koyejo, and Indranil Gupta. Zeno: Distributed stochastic
gradient descent with suspicion-based fault-tolerance. In _Proceedings of the_
_International Conference on Machine Learning_, 2019.

[93] Cong Xie, Oluwasanmi Koyejo, and Indranil Gupta. Zeno++: Robust fully asynchronous SGD. In _Proceedings of the International Conference on Machine Learning_,
2020.

[94] Dong Yin, Yudong Chen, Ramchandran Kannan, and Peter Bartlett. Byzantinerobust distributed learning: Towards optimal statistical rates. In _International_
_Conference on Machine Learning (ICML)_, 2019.

[95] Hongxu Yin, Arun Mallya, Arash Vahdat, JosÃ© Manuel Ãlvarez, Jan Kautz, and
Pavlo Molchanov. See through gradients: Image batch recovery via gradinversion.
_2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)_,
pages 16332â€“16341, 2021.

[96] Zalando. Fashion mnist.

[97] Ligeng Zhu, Zhijian Liu, and Song Han. Deep leakage from gradients. In _NeurIPS_,
2019.

[98] Richard Zippel. Probabilistic algorithms for sparse polynomials. In _Proceed-_
_ings of the International Symposiumon on Symbolic and Algebraic Computation_,
EUROSAM â€™79, page 216â€“226, Berlin, Heidelberg, 1979. Springer-Verlag.


E FFeL: Ensuring Integrity For Federated Learning CCS â€™22, November 7â€“11, 2022, Los Angeles, CA, USA



**Table 4: Notations**


Symbol Description


_ğ‘›_ Total number of clients

_ğ‘š_ Number of malicious clients

S Server

C _ğ‘–_ _ğ‘–_ -th client
_ğ·_ _ğ‘–_ Private dataset of C _ğ‘–_

C Set of all _ğ‘›_ clients

C _ğ»_ Set of _ğ‘›_ âˆ’ _ğ‘š_ honest clients
C _ğ‘€_ Set of _ğ‘š_ malicious clients
Valid(Â·) Validation predicate
M Global model to be trained

_ğ‘¢_ _ğ‘–_ Local update (gradient) of client C _ğ‘–_
U Aggregate update
C Valid Set of clients such that for all C _ğ‘–_ âˆˆC Valid, Valid( _ğ‘¢_ _ğ‘–_ ) = 1
U Valid Aggregate of valid updates only U Valid = [ï¿½] C _ğ‘–_ âˆˆC Valid _[ğ‘¢]_ _ğ‘–_
_ğœ…_ Security parameter
( _ğ‘–,ğ‘ _ _ğ‘–_ ) _ğ‘–_ -th Shamirâ€™s secret share for a secret _ğ‘ _ âˆˆ F
Î¨ Check string for the verifiable secret sharing
_ğ‘ğ‘_ Public parameters of the cryptographic protocols
_ğ‘ğ‘˜_ Public key
_ğ‘ ğ‘˜_ Secret key
_ğ‘ ğ‘˜_ _ğ‘–ğ‘—_ Shared secret key between clients C _ğ‘–_ and C _ğ‘—_
P Prover in the SNIP protocol
V _ğ‘–_ _ğ‘–_ -th verifier in the SNIP protocol
_ğœ‹_ SNIP proof
_â„_ / _ğ‘“_ / _ğ‘”_ Polynomials generated by P for the construction of _ğœ‹_
( _ğ‘,ğ‘,ğ‘_ ) Beaverâ€™s triplet generated by P for the construction of _ğœ‹_

[ _ğ‘ _ ] _ğ‘–_ _ğ‘–_ -th additive secret share for a secret _ğ‘ _ âˆˆ F
_ğ‘¤_ _[ğ‘œğ‘¢ğ‘¡]_ Value of the output wire of the circuit Valid(Â·)
_ğœ_ Proof summary broadcasted by the verifiers
F A prime field
M Number of multiplication gates in Valid(Â·)
B Public bulletin board
C \ _ğ‘–_ Set of all clients except C _ğ‘–_, C \ _ğ‘–_ = C \ C _ğ‘–_
C [âˆ—] List of malicious clients maintained by S in EIFFeL
( _ğ‘—,ğ‘ _ _ğ‘–ğ‘—_ ) Client C _ğ‘—_ â€™s (Shamir secret) share of client C _ğ‘–_ â€™s secret _ğ‘ _ _ğ‘–_ âˆˆ F in EIFFeL
_ğœ‹_ _ğ‘–_ Client C _ğ‘–_ â€™s proof in EIFFeL
_â„_ _ğ‘–_ / _ğ‘“_ _ğ‘–_ / _ğ‘”_ _ğ‘–_ Polynomials generated by client C _ğ‘–_ for the construction of _ğœ‹_ _ğ‘–_ in EIFFeL
( _ğ‘_ _ğ‘–_ _,ğ‘_ _ğ‘–_ _,ğ‘_ _ğ‘–_ ) Beaverâ€™s triplet generated by client C _ğ‘–_ for the construction of _ğœ‹_ _ğ‘–_ in EIFFeL
_ğ‘¤_ _ğ‘–_ _[ğ‘œğ‘¢ğ‘¡]_ Value of the output wire of the circuit Valid( _ğ‘¢_ _ğ‘–_ ) for client C _ğ‘–_
Î¨ _ğœ‹_ _ğ‘–_ Check string generated by client C _ğ‘–_ for the shares of their proof _ğœ‹_ _ğ‘–_
Î¨ _ğ‘¢_ _ğ‘–_ Check string generated by client C _ğ‘–_ for the shares of their update _ğ‘¢_ _ğ‘–_
_ğœ_ _ğ‘—ğ‘–_ Client C _ğ‘—_ â€™s shar of the summary for client C _ğ‘–_ â€™s proof in EIFFeL
_ğœ†_ _ğ‘—ğ‘–_ Client C _ğ‘—_ â€™s share of the random digest for client C _ğ‘–_ â€™s proof in EIFFeL
_ğœ†_ _ğ‘–_ Client C _ğ‘–_ â€™s random digest reconstructed from the shares { _ğœ†_ _ğ‘—ğ‘–_ } _, ğ‘—_ âˆˆC \ _ğ‘–_
_ğœ_ _ğ‘–_ Client C _ğ‘–_ â€™s proof summary reconstructed from the shares { _ğœ_ _ğ‘—ğ‘–_ } _, ğ‘—_ âˆˆC \ _ğ‘–_

**11** **Appendix**


**11.1** **Building Blocks Cntd.**


**Arithmetic Circuit.** An arithmetic circuit, C : F _[ğ‘˜]_ â†¦â†’ F, represents a
computation over a finite field F . It can be represented by a directed
acyclic graph (DAG) consisting of three types of nodes: ( 1 ) inputs,
( 2 ) gates and ( 3 ) outputs. Input nodes have in-degree zero and outdegree one: the _ğ‘˜_ input nodes return input variables { _ğ‘¥_ 1 _,_ - Â· Â· _,ğ‘¥_ _ğ‘˜_ }
with _ğ‘¥_ _ğ‘–_ âˆˆ F . Gate nodes have in-degree two and out-degree one;
they perform either the + operation (addition gate) or the Ã— operation (multiplication gate). Every circuit has a single output node
with out-degree zero. A circuit is evaluated by traversing the DAG,
starting from the inputs, and assigning a value in F to every wire
until the output node is evaluated.


**Shamirâ€™s Secret Sharing Scheme.** The scheme is _additive_, _i.e._, it
allows addition of two secret shared values locally. Formally, for all
_ğ‘ ,ğ‘¤_ âˆˆ F and _ğ‘„_ âŠ† _ğ‘ƒ,_ | _ğ‘„_ | â‰¤ _ğ‘¡_ :


_ğ‘ _ + _ğ‘¤_ â† SS.recon({( _ğ‘–,ğ‘ _ _ğ‘–_ + _ğ‘¤_ _ğ‘–_ ) _ğ‘–_ âˆˆ _ğ‘„_ }) (7)


Additionally, the scheme is a linear secret sharing scheme which
means that any linear operations performed on the individual shares



translates to operations performed on the secret, upon reconstruction. Specifically, for _ğ‘„_ âŠ† _ğ‘ƒ,_ | _ğ‘„_ | â‰¥ _ğ‘¡_ and _ğ›¼, ğ›½_ âˆˆ F:


_ğ›¼ğ‘ _ + _ğ›½_ â† SS.recon({( _ğ‘–, ğ›¼ğ‘ _ _ğ‘–_ + _ğ›½_ ) _ğ‘–_ âˆˆ _ğ‘„_ }) (8)


This means that a party can perform linear operations on the secret
_locally_ .


_Verifiable Secret Shares._ To make the Shamirâ€™s Secret shares verifiable, we use Feldmanâ€™s [ 35 ] VSS technique. Let _ğ‘_ ( _ğ‘¥_ ) = _ğ‘_ 0 + _ğ‘_ 1 _ğ‘¥_ +

- Â· Â· _ğ‘_ _ğ‘¡_ âˆ’1 _ğ‘¥_ _[ğ‘¡]_ [âˆ’][1] denote the polynomial used in generating the shares
where _ğ‘_ 0 = _ğ‘ _ is the secret. The check string are the commitments
to the coeffcients given by


_ğœ“_ _ğ‘–_ = _ğ‘”_ _[ğ‘]_ _[ğ‘–]_ _,ğ‘–_ âˆˆ{0 _,_        - Â· Â· _,ğ‘¡_ âˆ’ 1} (9)


where _ğ‘”_ denotes a generator of F . All arithmetic is taken modulo _ğ‘_
such that ( _ğ‘_ | _ğ‘_ âˆ’ 1) where _ğ‘_ is the prime of F.


For verifiying a share ( _ğ‘—,ğ‘ _ _ğ‘—_ ), a party needs to check whether _ğ‘”_ _[ğ‘ ]_ _[ğ‘—]_ =
ï¿½ _ğ‘–ğ‘¡_ =âˆ’01 _[ğœ“]_ _ğ‘–_ _[ğ‘—]_ _[ğ‘–]_ [. The privacy of the secret] _[ ğ‘ ]_ [=] _[ ğ‘]_ [0] [ is implied by the the]
intractability of computing discrete logarithms [35].


**Short Non-Interactive Proofs (SNIP).** Here, we detail the SNIP
protocols. SNIP works in two stages as follows:


_(1) Generation of Proof._ The prover P evaluates the circuit Valid(Â·)
on its input _ğ‘¥_ to obtain the value that every wire in the circuit takes
on during the computation of Valid( _ğ‘¥_ ) . Using these wire values,
P constructs three randomized polynomials _ğ‘“_, _ğ‘”_, and _â„_, which
encode the values of the input and output wires of each of the M
multiplication gates in the computation of Valid( _ğ‘¥_ ).


Let us label the _ğ‘€_ multiplication gates in the Valid(Â·) circuit in
the topological order from inputs to outputs as { 1 _,_ - Â· Â· _,_ M} . Let
_ğ‘¢_ _ğ‘¡_ and _ğ‘£_ _ğ‘¡_ denote the values on the left and right input wires of
the _ğ‘¡_ -th multiplication gate for _ğ‘¡_ âˆˆ[ _ğ‘€_ ] . The prover P samples
two values _ğ‘¢_ 0 and _ğ‘£_ 0 uniformly at random from F . _ğ‘“_ and _ğ‘”_ are
defined to be the lowest degree polynomials such that _ğ‘“_ ( _ğ‘¡_ ) = _ğ‘¢_ _ğ‘¡_
and _ğ‘”_ ( _ğ‘¡_ ) = _ğ‘£_ _ğ‘¡_ _,_ âˆ€ _ğ‘¡_ âˆˆ[M] . Next, _â„_ is defined as the polynomial
_â„_ = _ğ‘“_ - _ğ‘”_ . The polynomials _ğ‘“_ and _ğ‘”_ has degree at most _ğ‘€_ and the
polynomial _â„_ has degree at most 2 M . It is easy to see that _â„_ ( _ğ‘¡_ )
is the value of the output wire ( _ğ‘¢_ _ğ‘¡_ - _ğ‘£_ _ğ‘¡_ ) of the _ğ‘¡_ -th multiplication
gate in the Valid( _ğ‘¥_ ) circuit since _â„_ ( _ğ‘¡_ ) = _ğ‘“_ ( _ğ‘¡_ ) Â· _ğ‘”_ ( _ğ‘¡_ ) = _ğ‘¢_ _ğ‘¡_ - _ğ‘£_ _ğ‘¡_ _,_ âˆ€ _ğ‘¡_ âˆˆ

[M] . The prover P can construct the polynomials _ğ‘“_ and _ğ‘”_ using
polynomial interpolation and can multiply them produce _â„_ = _ğ‘“_ _ğ‘”_ . Additionally, P samples a single set of Beaverâ€™s multiplication
triples [ 7 ]: ( _ğ‘,ğ‘,ğ‘_ ) âˆˆ F [3] such that _ğ‘_ - _ğ‘_ = _ğ‘_ âˆˆ F . Prover P constructs
the proof share [ _ğœ‹_ ] _ğ‘–_ = âŸ¨[ _ğ‘“_ ( 0 )] _ğ‘–_ _,_ [ _ğ‘”_ ( 0 )] _ğ‘–_ _,_ [ _â„_ ] _ğ‘–_ _,_ ([ _ğ‘_ ] _ğ‘–_ _,_ [ _ğ‘_ ] _ğ‘–_ _,_ [ _ğ‘_ ] _ğ‘–_ )âŸ© [1] for
verifier V _ğ‘–_ by splitting:


 - the random values _ğ‘“_ ( 0 ) = _ğ‘¢_ 0 and _ğ‘”_ ( 0 ) = _ğ‘£_ 0, using additive
secret sharing,


 - the coefficients of _â„_ (denoted by [ _â„_ ] _ğ‘–_, and


 - the sampled Beaverâ€™s triplets ( _ğ‘,ğ‘,ğ‘_ ).


The prover then sends the respective shares of the input and the
proof ([ _ğ‘¥_ ] _ğ‘–_ _,_ [ _ğœ‹_ ] _ğ‘–_ ) to each of the verifiers V _ğ‘–_ .


1 Note that we omitted the terms [ _ğ‘“_ (0)] _ğ‘–_ and [ _ğ‘”_ (0)] _ğ‘–_ from _ğœ‹_ _ğ‘–_ in Sec. 4.1 for the ease
of exposition.


CCS â€™22, November 7â€“11, 2022, Los Angeles, CA, USA Roy Chowdhury et al.



_(2) Verification of Proof._ Using [ _ğ‘¥_ ] _ğ‘–_, the share of the proversâ€™s
private value _ğ‘¥_, and [ _ğ‘“_ ( 0 )] _ğ‘–_, [ _ğ‘”_ ( 0 )] _ğ‘–_, and [ _â„_ ] _ğ‘–_, each verifier V _ğ‘–_ can
_locally_ (i.e., without communicating with the other verifiers/prover)
produce shares [ _ğ‘“_ ] _ğ‘–_ and [ _ğ‘”_ ] _ğ‘–_ of the polynomials _ğ‘“_ and _ğ‘”_ as follows:


 - V _ğ‘–_ reconstructs a share of every wire for the Valid( _ğ‘¥_ ) circuit.
This is possible since V _ğ‘–_ has access to ( 1 ) a share of each of
the input wire values ([ _ğ‘¥_ ] _ğ‘–_ ) and ( 2 ) a share of each wire value
coming out of a multiplication gate ([ _â„_ ] _ğ‘–_ ( _ğ‘¡_ ) _,ğ‘¡_ âˆˆ[M] is a share
of the _ğ‘¡_ -th such wire). Hence, V _ğ‘–_ can derive all other wire value
shares via affine operations on the wire value shares it already
has.


 - Using these wire value shares and shares of _ğ‘“_ (0) and _ğ‘”_ (0), V _ğ‘–_
uses polynomial interpolation to construct [ _ğ‘“_ ] _ğ‘–_ and [ _ğ‘”_ ] _ğ‘–_


To verify that Valid( _ğ‘¥_ ) = 1 and hence, accept the input _ğ‘¥_, the
verifiers need to check two things:


 - check the consistency of Pâ€™s computation of Valid( _ğ‘¥_ ), and


 - check that the value of final output wire of the computation,
Valid( _ğ‘¥_ ), denoted by _ğ‘¤_ _[ğ‘œğ‘¢ğ‘¡]_ is indeed 1.


For carrying out the above mentioned checks, the verifier V _ğ‘–_ broadcasts a summary _ğœ_ _ğ‘–_ = ([ _ğ‘¤_ _[ğ‘œğ‘¢ğ‘¡]_ ] _ğ‘–_ _,_ [ _ğœ†_ ] _ğ‘–_ ), where [ _ğ‘¤_ _[ğ‘œğ‘¢ğ‘¡]_ ] _ğ‘–_ is V _ğ‘–_ â€™s share
of the output wire and [ _ğœ†_ ] _ğ‘–_ is a share of a random digest that the
verifier computes from the shares of the other wire values and the
proof share _ğœ‹_ _ğ‘–_ . The details are discussed as follows:


_(2a) Checking the Consistency of_ P _â€™s Computation of_ _Valid_ ( _ğ‘¥_ ) _._ For
honest provers and verifiers, the verifiers will now hold shares of
polynomials _ğ‘“_, _ğ‘”_, and _â„_ such that _ğ‘“_ - _ğ‘”_ = _â„_ . In contrast, a malicious
_â„_ prover could have sent the verifiers shares of a different polynomial Ë† such that, for some _ğ‘¡_ âˆˆ[ _ğ‘€_ ] _,â„_ Ë† ( _ğ‘¡_ ) is not the value on the output
wire in the _ğ‘¡_ -th multiplication gate of the V( _ğ‘¥_ ) circuit. In this case,
the verifiers end up reconstructing shares of polynomials _ğ‘“_ [Ë†] and
_ğ‘”_ Ë† that might not be equal to _ğ‘“_ and _ğ‘”_ . Then, we have _â„_ [Ë†] â‰  _ğ‘“_ [Ë†] - Ë† _ğ‘”_ as
explained below. Consider the least _ğ‘¡_ [â€²] for which _â„_ [Ë†] ( _ğ‘¡_ [â€²] ) â‰  _â„_ ( _ğ‘¡_ [â€²] ) . For
all _ğ‘¡_ â‰¤ _ğ‘¡_ [â€²], _ğ‘“_ [Ë†] ( _ğ‘¡_ ) = _ğ‘“_ ( _ğ‘¡_ ) and _ğ‘”_ ( _ğ‘¡_ ) = _ğ‘”_ ( _ğ‘¡_ ), by construction. Since,


Ë†
_â„_ ( _ğ‘¡_ [â€²] ) â‰  _â„_ ( _ğ‘¡_ [â€²] ) = _ğ‘“_ ( _ğ‘¡_ [â€²] ) Â· _ğ‘”_ ( _ğ‘¡_ [â€²] ) = Ë† _ğ‘“_ ( _ğ‘¡_ ) [â€²]     - Ë† _ğ‘”_ ( _ğ‘¡_ [â€²] ) _,_ (10)


it must be that _â„_ [Ë†] ( _ğ‘¡_ [â€²] ) â‰  _ğ‘“_ [Ë†] ( _ğ‘¡_ [â€²] ) Â· Ë† _ğ‘”_ ( _ğ‘¡_ [â€²] ), so _â„_ [Ë†] â‰  _ğ‘“_ [Ë†] - Ë† _ğ‘”._ The verifiers can
employ the above check using the Schwartz-Zippel randomized
polynomial identity test [74, 98] as explained later in this section.


_(2b) Output Verification._ In case all the verifiers are honest, each
V _ğ‘–_ now holds a set of shares of the values of all the wires of the
Valid( _ğ‘¥_ ) circuit. So to confirm that Valid( _ğ‘¥_ ) = 1, the verifiers need
only broadcast their shares of the output wire _ğ‘¤_ _ğ‘–_ _[ğ‘œğ‘¢ğ‘¡]_ . The verifiers
can thus reconstruct its exact value from all the broadcasted shares
_ğ‘¤_ _[ğ‘œğ‘¢ğ‘¡]_ = [ï¿½] _[ğ‘˜]_ _ğ‘–_ =1 [[] _[ğ‘¤]_ _[ğ‘œğ‘¢ğ‘¡]_ []] _[ğ‘–]_ [and check whether] _[ ğ‘¤]_ _[ğ‘œğ‘¢ğ‘¡]_ [=] [ 1, in which case it]
must be that Valid( _ğ‘¥_ ) = 1 (except with some small failure probability due to the polynomial identity test).


_Polynomial Identity Test_ . Recall that each verifier V _ğ‘–_ holds shares

[ _ğ‘“_ [Ë†] ] _ğ‘–_, [ _ğ‘”_ Ë†] _ğ‘–_ and [ _â„_ [Ë†] ] _ğ‘–_ of the polynomials _ğ‘“_ [Ë†], Ë† _ğ‘”_ and _â„_ [Ë†] . Furthermore, it
holds that _ğ‘“_ [Ë†] - Ë† _ğ‘”_ = _â„_ [Ë†] if and only the set of the wire value shares,
held by the verifiers, sum up to the internal wire values of the



Valid( _ğ‘¥_ ) circuit computation. The verifiers now execute a variant
of the Schwartz-Zippel randomized polynomial identity test to
check whether this relation holds. The main idea of the test is that
if _ğ‘“_ [Ë†] ( _ğ‘¡_ )Â· _ğ‘”_ Ë†( _ğ‘¡_ ) â‰  _â„_ [Ë†] ( _ğ‘¡_ ), then the polynomial _ğ‘¡_ - ( _ğ‘“_ [Ë†] ( _ğ‘¡_ )Â· _ğ‘”_ Ë†( _ğ‘¡_ )âˆ’ _â„_ [Ë†] ( _ğ‘¡_ )) is a nonzero polynomial of degree at most 2 M+ 1. (The utility of multiplying
the polynomial _ğ‘“_ [Ë†] - Ë† _ğ‘”_ âˆ’ _â„_ [Ë†] by _ğ‘¡_ is explained in the next paragraph)
Such a polynomial can have at most 2 M + 1 zeros in F, so for a _ğ‘Ÿ_ âˆˆ F
chosen at random and after evaluating _ğ‘Ÿ_ - ( _ğ‘“_ [Ë†] ( _ğ‘Ÿ_ ) Â· Ë† _ğ‘”_ ( _ğ‘Ÿ_ ) âˆ’ _â„_ [Ë†] ( _ğ‘Ÿ_ )), the
verifiers will detect that _ğ‘“_ [Ë†] - Ë† _ğ‘”_ â‰  _â„_ [Ë†] with probability at least 1 [2][M] |F [+] | [1] [.]


For the polynomial identity test, one of the verifiers samples a
random value _ğ‘Ÿ_ âˆˆ F and broadcasts it. Each verifier V _ğ‘–_ can locally
compute the shares [ _ğ‘“_ [Ë†] ( _ğ‘Ÿ_ )] _ğ‘–_, [ _ğ‘”_ Ë†( _ğ‘Ÿ_ )] _ğ‘–_, and [ _â„_ [Ë†] ( _ğ‘Ÿ_ )] _ğ‘–_ since polynomial
evaluation requires only affine operations. V _ğ‘–_ then applies a local
linear operation to these last two shares to obtain the shares [ _ğ‘Ÿ_ _ğ‘”_ Ë†( _ğ‘Ÿ_ )] _ğ‘–_ and [ _ğ‘Ÿ_ - _â„_ [Ë†] ( _ğ‘Ÿ_ )] _ğ‘–_ .


_Multiplication of Shares._ Note that the verifiers need to securely multiply their shares [ _ğ‘“_ [Ë†] ( _ğ‘Ÿ_ )] _ğ‘–_ and [ _ğ‘Ÿ_ - Ë† _ğ‘”_ ( _ğ‘Ÿ_ )] _ğ‘–_ to get a share [ _ğ‘Ÿ_ - _ğ‘“_ [Ë†] ( _ğ‘Ÿ_ )Â· Ë† _ğ‘”_ ( _ğ‘Ÿ_ )] _ğ‘–_
without leaking anything to each other about the values _ğ‘“_ [Ë†] ( _ğ‘Ÿ_ ) and
_ğ‘”_ Ë†( _ğ‘Ÿ_ ) . This can be performed via the Beaverâ€™s MPC multiplication
protocol (described later). Using this protocol, verifiers with access to one-time-use shares ([ _ğ‘_ ] _ğ‘–_ _,_ [ _ğ‘_ ] _ğ‘–_ _,_ [ _ğ‘_ ] _ğ‘–_ ) âˆˆ F [3] of random values
such that _ğ‘_ - _ğ‘_ = _ğ‘_ âˆˆ F (â€œmultiplication triplesâ€), can execute a
multi-party multiplication of a pair of secret-shared values. For
SNIPs, the prover P generates the multiplication triple on behalf
of the verifiers and sends shares of these values to each verifier. If

P produces the shares of these values correctly, then the verifiers
can perform a multi-party multiplication of shares to complete
the correctness check as discussed above. More importantly, we
can ensure that even if P sends shares of an invalid multiplication
triple, the verifiers will still catch the cheating prover with high
probability. Letâ€™s assume that the cheating prover sends the shares
([ _ğ‘_ ] _ğ‘–_ _,_ [ _ğ‘_ ] _,_ [ _ğ‘_ ] _ğ‘–_ ) âˆˆ F [3] such that _ğ‘_ - _ğ‘_ â‰  _ğ‘_ âˆˆ F . Let _ğ‘_ - _ğ‘_ = ( _ğ‘_ + _ğ›¼_ ) âˆˆ F,
for some constant _ğ›¼_ _>_ 0. Executing the polynomial identity test
using the above triples will shift the result of the test by _ğ›¼_ . So the
verifiers will be effectively testing whether the polynomial


Ë† Ë†
_ğ‘„_ ( _ğ‘¡_ ) = _ğ‘¡_      - ( Ë† _ğ‘“_ ( _ğ‘¡_ ) Â· Ë† _ğ‘”_ ( _ğ‘¡_ ) âˆ’ _â„_ ( _ğ‘¡_ )) + _ğ›¼_ (11)


is identically zero. Whenever Ë† _ğ‘“_ [Ë†] - Ë† _ğ‘”_ â‰  _â„_ [Ë†], it holds that Ë† _ğ‘¡_ - ( _ğ‘“_ [Ë†] ( _ğ‘¡_ ) Â· Ë† _ğ‘”_ ( _ğ‘¡_ ) âˆ’
_â„_ ( _ğ‘¡_ )) is a non-zero polynomial. So, if Ë† _ğ‘“_ - _ğ‘”_ Ë† â‰  _â„_, then Ë† _ğ‘„_ ( _ğ‘¡_ ) must also be
a non-zero polynomial. Note that the multiplying the term â€ _ğ‘“_ [Ë†] - Ë† _ğ‘”_ âˆ’ _â„_ [Ë†] â€
by _ğ‘¡_ ensures that whenever this expression is non-zero, the resulting
polynomial _ğ‘„_ [Ë†] is guaranteed to be non-zero, even if _ğ‘“_ [Ë†], Ë† _ğ‘”_, and _â„_ [Ë†]
are constants, and the prover chooses _ğ›¼_ adversarially. Since SNIP
assumes honest verifiers, we may assume that the prover did not
know the random value _ğ‘Ÿ_ while generating its multiplication triple.
This implies that _ğ‘Ÿ_ is distributed independently of _ğ›¼_ which means
that we will catch a cheating prover with probability 1 âˆ’ [2] _[ğ‘€]_ |F [+] | [1] [.]


**Beaverâ€™s MPC Multiplication Protocol.** SNIP uses Beaverâ€™s multiplication triples as follows. A multiplication triple is a one-timeuse triple of values ( _ğ‘,ğ‘,ğ‘_ ) âˆˆ F [3], chosen at random subject to the
constraint that _ğ‘_ - _ğ‘_ = _ğ‘_ âˆˆ F . In SNIP, computation, each verifier V _ğ‘–_
holds a share ([ _ğ‘_ ] _ğ‘–_ _,_ [ _ğ‘_ ] _ğ‘–_ _,_ [ _ğ‘_ ] _ğ‘–_ ) âˆˆ F [3] of the triple. Using their shares
of one such triple ( _ğ‘,ğ‘,ğ‘_ ), the verifiers can jointly evaluate shares
of the output of a multiplication gate _ğ‘¦ğ‘§_ . To do so, each verifier uses


E FFeL: Ensuring Integrity For Federated Learning CCS â€™22, November 7â€“11, 2022, Los Angeles, CA, USA



its shares [ _ğ‘¦_ ] _ğ‘–_ and [ _ğ‘§_ ] _ğ‘–_ of the input wires, along with the first two
components of its multiplication triple to compute the following
values:


[ _ğ‘‘_ ] _ğ‘–_ = [ _ğ‘¦_ ] _ğ‘–_ âˆ’[ _ğ‘_ ] _ğ‘–_ (12)


[ _ğ‘’_ ] _ğ‘–_ = [ _ğ‘§_ ] _ğ‘–_ âˆ’[ _ğ‘_ ] _ğ‘–_ (13)


Each verifier V _ğ‘–_ then broadcasts [ _ğ‘‘_ ] _ğ‘–_ and [ _ğ‘’_ ] _ğ‘–_ . Using the broadcasted shares, every verifier can reconstruct _ğ‘‘_ and _ğ‘’_ and can com
pute:


[ _ğœ†_ ] _ğ‘–_ = _ğ‘‘ğ‘’_ / _ğ‘˜_ + _ğ‘‘_ [ _ğ‘_ ] _ğ‘–_ + _ğ‘’_ [ _ğ‘_ ] _ğ‘–_ + [ _ğ‘_ ] _ğ‘–_ (14)


Clearly, [ï¿½] _[ğ‘˜]_ _ğ‘–_ =1 [[] _[ğœ†]_ []] _[ğ‘–]_ [=] _[ ğ‘¦ğ‘§]_ [. Thus, this step requires a round of commu-]
nication for the broadcast and three reconstructions for _ğ‘‘_, _ğ‘’_ and

_ğœ†_ .


For SNIPs on Shamirâ€™s secret shares, the verifier V _ğ‘–_ compute the
shares ( _ğ‘–, ğœ†_ _ğ‘–_ ) where _ğœ†_ _ğ‘–_ = _ğ‘‘ğ‘’_ + _ğ‘‘ğ‘_ _ğ‘–_ + _ğ‘’ğ‘_ _ğ‘–_ + _ğ‘_ _ğ‘–_ which gives _ğ‘¦ğ‘§_ â†
SS.recon(( _ğ‘–, ğœ†_ _ğ‘–_ )).


As mentioned in Sec. 6, we can leverage the multiplicativity of
Shamirâ€™s secret shares to generate _ğœ†_ _ğ‘–_ for client C _ğ‘–_ locally. Specifically, each client can locally multiply the shares ( _ğ‘—, ğ‘“_ _ğ‘–ğ‘—_ ) and ( _ğ‘—,ğ‘”_ _ğ‘–ğ‘—_ )
to generate ( _ğ‘–,_ ( _ğ‘“_ _ğ‘—_ - _ğ‘”_ _ğ‘—_ ) _ğ‘–_ ) . In order to make the shares consistent, C _ğ‘–_
multiplies the share of ( _ğ‘–,â„_ _ğ‘—ğ‘–_ ) with ( _ğ‘–,ğ‘§_ _ğ‘–_ ) where _ğ‘§_ = 1 (these can be
generated and shared by the server S in the clear). In this way, C _ğ‘—_
can locally generate a share of the digest ( _ğ‘—,ğ‘‘_ _ğ‘–ğ‘—_ ) that correspond
to a polynomial of degree 2 _ğ‘š_ . Since _ğ‘š_ _<_ _[ğ‘›]_ [âˆ’] ~~4~~ [1] [, this optimization is]

still compatible with robust reconstruction. In this way, we save
one round of communication and require only one reconstruction
for _ğœ†_ _ğ‘–_ instead of three.


**11.2** **Complexity Analysis**


We present the complexity analysis of EIFFeL in terms of the number of clients _ğ‘›_, number of malicious clients _ğ‘š_ and data dimension
_ğ‘‘_ (Table 1).


**Computation Cost.** Each client C _ğ‘–_ â€™s computation cost can be broken into six components: ( 1 ) performing _ğ‘›_ âˆ’1 key agreements â€“
_ğ‘‚_ ( _ğ‘›_ ) ; ( 2 ) generating proof _ğœ‹_ _ğ‘–_ for Valid( _ğ‘¢_ _ğ‘–_ ) = 1 â€“ _ğ‘‚_ (|Valid| + M log M) [2] ;
( 3 ) creating secret shares of the update _ğ‘¢_ _ğ‘–_ and the proof _ğœ‹_ _ğ‘–_ â€“
_ğ‘‚_ ( _ğ‘šğ‘›_ ( _ğ‘‘_ + M)) [3] ; ( 4 ) verifying the validity of the received shares
â€“ _ğ‘‚_ ( _ğ‘šğ‘›_ ( _ğ‘‘_ + M) ; ( 5 ) generating proof digest for all other clients â€“

_ğ‘‚_ ( _ğ‘›_ |Valid|) ; and ( 6 ) generating shares of the final aggregate â€“ _ğ‘‚_ ( _ğ‘›ğ‘‘_ ) .
Assuming |Valid| is of the order of _ğ‘‚_ ( _ğ‘‘_ ), the overall computation
complexity of each client C _ğ‘–_ is _ğ‘‚_ ( _ğ‘šğ‘›ğ‘‘_ ) .
The server S â€™s computation costs can be divided into three parts: ( 1 )
verifying the validity of the flagged shares â€“ _ğ‘‚_ ( _ğ‘šğ‘‘_ min( _ğ‘›,ğ‘š_ [2] )) ; ( 2 )
verifying the proof digest for all clients â€“ _ğ‘‚_ ( _ğ‘›_ [2] log [2] _ğ‘›_ log log _ğ‘›_ ) ; and
( 3 ) computing the final aggregate â€“ _ğ‘‚_ ( _ğ‘‘ğ‘›_ log [2] _ğ‘›_ log log _ğ‘›_ ) . Hence, the
total computation complexity of the server is _ğ‘‚_ [ï¿½] ( _ğ‘›_ + _ğ‘‘_ ) _ğ‘›_ log [2] _ğ‘›_ log log _ğ‘›_
+ _ğ‘šğ‘‘_ min( _ğ‘›,ğ‘š_ [2] ) [ï¿½] .


**Communication Cost.** The communication cost of each client C _ğ‘–_
has seven components: ( 1 ) exchanging keys with all other clients â€“
_ğ‘‚_ ( _ğ‘›_ ) ; ( 2 ) receiving Valid(Â·) â€“ _ğ‘‚_ (|Valid|) ; ( 3 ) sending encrypted secret
shares and check strings for all other clients â€“ _ğ‘‚_ ( _ğ‘›_ ( _ğ‘‘_ + M) + _ğ‘šğ‘‘_ ) ;


2 We use standard discrete FFT for all polynomial operations [38].
3 This uses the fact that the Lagrange coefficients can be pre-computed [58].



( 4 ) receiving encrypted secret shares and check strings from all
other clients â€“ _ğ‘‚_ ( _ğ‘›_ ( _ğ‘‘_ + M) + _ğ‘šğ‘›ğ‘‘_ ) ; ( 5 ) sending proof digests for every other client â€“ _ğ‘‚_ ( _ğ‘›_ ) ; ( 6 ) receiving the list of corrupt clients C
â€“ _ğ‘‚_ ( _ğ‘š_ ) ; and ( 7 ) sending the final aggregate â€“ _ğ‘‚_ ( _ğ‘‘_ ) . Thus, the communication complexity for every client is _ğ‘‚_ ( _ğ‘šğ‘›ğ‘‘_ ) .
The servers communication costs include: ( 1 ) sending the validation
predicate â€“ _ğ‘‚_ (|Valid|) ; ( 2 ) receiving check strings and secret shares
from flagged clients â€“ _ğ‘‚_ ( _ğ‘šğ‘‘_ min( _ğ‘›,ğ‘š_ [2] )) ; ( 3 ) receiving proof digests
â€“ _ğ‘‚_ ( _ğ‘›_ [2] ) ; ( 4 ) sending the list of malicious clients â€“ _ğ‘‚_ ( _ğ‘š_ ) ; and ( 5 ) receiving the shares of the final aggregate â€“ _ğ‘‚_ ( _ğ‘›ğ‘‘_ ) . Hence, the overall
communication complexity of the server is _ğ‘‚_ ( _ğ‘›_ [2] + _ğ‘šğ‘‘_ min( _ğ‘›,ğ‘š_ [2] )) .
The total number of one-way communication is 12 and 9 for the
clients and server, respectively, _independent_ of the complexity of
the validation predicate.


**11.3** **Proof for Lemma 3**


Proof. In Round 3, the proof corresponding to a client C _ğ‘–_ is verified
iff it has submitted valid shares for the _ğ‘›_ âˆ’ _ğ‘š_ âˆ’ 1 honest clients C _ğ»_ \C _ğ‘–_ .
This is clearly true if C _ğ‘–_ is honest. If C _ğ‘–_ is malicious, _i.e._, it submitted
at least one invalid share:


- _Case 1:_ |Flag[ _ğ‘–_ ]| â‰¥ _ğ‘š_ + 1 . It is clear that C _ğ‘–_ has submitted an invalid
share to at least one honest client and, hence, is removed from
the rest of the protocol.

- _Case 2:_ |Flag[ _ğ‘–_ ]| â‰¤ _ğ‘š_ . All honest clients in C _ğ»_ will be flagging C _ğ‘–_ .
Hence, C _ğ‘–_ either has to submit the corresponding valid shares or
be removed from the protocol.


Given _ğ‘›_ âˆ’ _ğ‘š_ âˆ’ 1 valid shares, using Fact 2, we know that EIFFeL reconstructs the proof summary for C _ğ‘–_ correctly. Eq. 5 then follows
from the soundness property of SNIP. 

**11.4** **Proof for Lemma 5**


Proof. In Round 2, observe that the shares ( _ğ‘—,ğ‘¢_ _ğ‘–ğ‘—_ ) _,_ ( _ğ‘—, ğœ‹_ _ğ‘–ğ‘—_ ) for each
client C _ğ‘—_ âˆˆC \ _ğ‘–_ are encrypted with the pairwise secret key and
distributed. Hence, a collusion of _ğ‘š_ malicious clients (and the server
S ) [4] can access _at most_ _ğ‘š_ shares of any honest client C _ğ‘–_ âˆˆC _ğ»_ . This
is true even in Round 3 where:


- A malicious client might falsely flag C _ğ‘–_ .

- No honest client in C _ğ»_ \ C _ğ‘–_ will flag C _ğ‘–_ since they would be
receiving valid shares (and their encryptions) from C _ğ‘–_ .

- S cannot lie about who flagged who, since everything is logged
publicly on the bulletin B.


Thus, only _ğ‘š_ shares of C _ğ‘–_ can be revealed which correspond to the
_ğ‘š_ malicious clients.

Since at least _ğ‘š_ + 1 shares are required to recover the secret, any
instantiation of the SNIP verification protocol ( _i.e._, reconstruction
of the values of _ğœ_ _ğ‘–_ = ( _ğ‘¤_ _ğ‘–_ _[ğ‘œğ‘¢ğ‘¡]_ _, ğœ†_ _ğ‘–_ ) ) requires at least one _honest_ client
to act as the verifier. Hence, at the end of Round 3, from Fact 1
and the zero-knowledge property of SNIP, the only information
revealed is that Valid( _ğ‘¢_ _ğ‘–_ ) = 1. 

4 The server does not have access to any share of its own in EIFFeL.


CCS â€™22, November 7â€“11, 2022, Los Angeles, CA, USA Roy Chowdhury et al.



**11.5** **Security Proof**


Theorem 7. _Given a public validation predicate_ _Valid_ (Â·) _, security_
_parameter_ _ğœ…_ _, set of_ _ğ‘š_ _malicious clients_ C _ğ‘€_ _,_ âŒŠ _ğ‘š_ _<_ _[ğ‘›]_ [âˆ’] ~~3~~ [1] [âŒ‹] _[and a ma-]_

_licious server_ S _, there exists a probabilistic polynomial-time (P.P.T.)_
_simulator Sim_ (Â·) _such that:_


_Real_ _EIFFeL_ ï¿½{ _ğ‘¢_ C _ğ»_ } _,_ Î© C _ğ‘€_ âˆªS ï¿½ â‰¡ _ğ¶_ _Sim_ ï¿½Î© C _ğ‘€_ âˆªS _,_ U _ğ»_ _,_ C _ğ»_ ï¿½


_where_ U _ğ»_ = _ğ‘¢_ _ğ‘–_ _._
âˆ‘ï¸

C _ğ‘–_ âˆˆC _ğ»_


{ _ğ‘¢_ C _ğ»_ } _denotes the input of all the honest clients,_ _Real_ _EIFFeL_ _denotes_
_a random variable representing the joint view of all the parties in_
_EIFFeLâ€™s execution,_ Î© C _ğ‘€_ âˆªS _indicates a polynomial-time algorithm_
_implementing the â€œnext-messageâ€ function of the parties in_ C _ğ‘€_ âˆªS _,_
_and_ â‰¡ _ğ¶_ _denotes computational indistinguishability._


Proof. We prove the theorem by a standard hybrid argument. Let
Î© C _ğ‘€_ âˆªS indicate the polynomial-time algorithm that denotes the
â€œnext-messageâ€ function of parties in C _ğ‘€_ âˆªS . That is, given a party
identifier _ğ‘_ âˆˆC _ğ‘€_ âˆªS, a round index _ğ‘–_, a transcript _ğ‘‡_ of all messages
sent and received so far by all parties in C _ğ‘€_ âˆªS, joint randomness
_ğ‘Ÿ_ C _ğ‘€_ âˆªS for the corrupt partiesâ€™ execution, and access to random
oracle _ğ‘‚_, Î© C _ğ‘€_ âˆªS ( _ğ‘,ğ‘–,ğ‘‡,ğ‘Ÿ_ C _ğ‘€_ âˆªS ) outputs the message for party _ğ‘_
in round _ğ‘–_ (possibly making several queries to _ğ‘‚_ along the way).
We note that Î© C _ğ‘€_ âˆªS is thus effectively choosing the inputs for all
corrupt users.


We will define a simulator Sim through a series of (polynomially
many) subsequent modifications to the real execution Real EIFFeL,
so that the views of Î© C _ğ‘€_ âˆªS in any two subsequent executions are
computationally indistinguishable.


(1) Hyb 0 : This random variable is distributed exactly as the view
of Î© C _ğ‘€_ âˆªS in Real EIFFeL, the joint view of the parties C _ğ‘€_ âˆªS
in a real execution of the protocol.


(2) Hyb 1 : In this hybrid, for any pair of honest clients C _ğ‘–_ _,_ C _ğ‘—_ âˆˆC _ğ»_,
the simulator changes the key from KA.agree( _ğ‘ğ‘˜_ _ğ‘—_ _,ğ‘ ğ‘˜_ _ğ‘–_ ) to a
uniformly random key. We use Diffie-Hellman key exchange
protocol in EIFFeL. The DDH assumption [ 32 ] guarantees that
this hybrid is indistinguishable from the previous one. also be
able to break the DDH.


(3) Hyb 2 : This hybrid is identical to Hyb 1, except additionally, Sim
will abort if Î© C _ğ‘€_ âˆªS succeeds to deliver, in round 2, a message
to an honest client C _ğ‘–_ on behalf of another honest client C _ğ‘—_,
such that ( 1 ) the message is different from that of Sim, and
( 2 ) the message does not cause the decryption to fail. Such a
message would directly violate the IND-CCA security of the
encryption scheme.


(4) Hyb 3 : In this round, for every honest party in C _ğ»_, Sim samples
_ğ‘ _ _ğ‘–_ âˆˆ F such that Valid( _ğ‘ _ _ğ‘–_ ) = 1 and replaces all the shares and the
check strings accordingly. This allows the server to compute
the _ğœ_ _ğ‘–_ = ( _ğ‘¤_ _ğ‘–_ _[ğ‘œğ‘¢ğ‘¡]_ _, ğœ†_ _ğ‘–_ ) such that _ğ‘¤_ _ğ‘–_ _[ğ‘œğ‘¢ğ‘¡]_ = 1 âˆ§ _ğœ†_ _ğ‘–_ = 0 for all honest
clients in the same way as in the previous hybrid. An adversary
noticing any difference would break ( 1 ) the computational
discrete logarithm assumption used by the VSS [ 35 ], OR ( 2 )
the IND-CCA guarantee of the encryption scheme, OR ( 3 ) the
information theoretic perfect secrecy of Shamirâ€™s secret sharing



scheme with threshold _ğ‘š_ + 1, OR ( 4 ) zero-knowledge property
of SNIP.


(5) Hyb 4 : In this hybrid, Sim uses U _ğ»_ to compute the following
polynomial. Let ( _ğ‘—,ğ‘†_ _ğ‘—_ ) represent the share of [ï¿½] _ğ‘–_ âˆˆC _ğ»_ _[ğ‘ ]_ _ğ‘–_ [for a]
malicious client C _ğ‘—_ âˆˆC \ C _ğ»_ where _ğ‘ _ _ğ‘–_ denotes the random
input Sim had sampled for C _ğ‘–_ âˆˆC _ğ»_ in Hyb 3 . Sim performs
polynomial interpolation to find the _ğ‘š_ + 1-degree polynomial
_ğ‘_ âˆ— that satisfies _ğ‘_ âˆ—( 0 ) = U _ğ»_ and _ğ‘_ ( _ğ‘—_ ) = _ğ‘†_ _ğ‘—_ . Next, for all
honest client, Sim computes the share for U = U _ğ»_ + [ï¿½] C _ğ‘—_ âˆˆ _ğ¶_ [Â¯] _[ğ‘¢]_ _[ğ‘—]_
(Eq. 6) by using the polynomial _ğ‘_ âˆ— and the relevant messages
from Î© C _ğ‘€_ âˆªS . Clearly, this hybrid is indistinguishable from the
previous one by the perfect secrecy of Shamirâ€™s secret shares.
This concludes our proof.


                     

**11.6** **Additional Evaluation Results**


In this section, we provide some additional evaluation results on
model accuracy in Fig. 9. We use the same configuration as the one
reported in Sec. 7. Our observations are in line with our discussion
in Sec. 7.2.


**11.7** **Discussion Cntd.**


Here, we present additional avenues of future work for EIFFeL.


**Revealing Malicious Clients.** In our current implementation, EIFFeL publishes the (partial) list of malicious clients C [âˆ—] . To hide the
identity of malicious clients, we could include an equal number
of honest clients in the list before publishing it, thereby providing those clients plausible deniability. We leave more advanced
cryptographic solutions as a future direction.


**Private Validation Predicate.** If Valid(Â·) contains some secrets of
the server S, we can employ multiple servers where the computation of Valid( _ğ‘¢_ ) is done at the servers [ 28 ]. We leave a single-server
solution of this problem for future work.


**Byzantine-Robust Aggregation.** In EIFFeL, the integrity check
is done individually on each client update, independent of all other
clients. An alternative approach to compare the local model updates
of _all_ the clients (via pairwise distance/ cosine similarity) [ 14, 15, 24,
33, 34 ] and remove statistical outliers before using them to update
the global model. A general framework to support secure Byzantinerobust aggregations rules, such as above, is an interesting future
direction.


**Valid** (Â·) **Structure.** If Valid(Â·) contains repeated structures, the _ğº_ gate technique [19] can improve efficiency.


**Complex Aggregation Rules.** EIFFeL can be used for more complex aggregation rules, such as mode, by extending SNIP with affineaggregatable encodings (AFE) [28].


**Differential Privacy.** The privacy guarantees of EIFFeL can be
enhanced by using differential privacy (DP) to reveal a _noisy_ aggregate using techniques such as [ 44 ]. Adding DP would also provide
additional robustness guarantees [64, 84].


E FFeL: Ensuring Integrity For Federated Learning CCS â€™22, November 7â€“11, 2022, Los Angeles, CA, USA







|100|Col2|
|---|---|
|20<br>40<br>60<br>80<br><br>Test Accuracy|~~00~~<br>~~200~~<br>~~300~~<br>~~400~~<br>~~500~~|
|20<br>40<br>60<br>80<br><br>Test Accuracy|Number of Iterations|


**(d) EMNIST: Additive noise attack with**
**Zeno++ similarity validation predicate.**

|80<br>Accuracy<br>60<br>40 Test<br>20<br>100|Col2|Col3|
|---|---|---|
|~~100~~<br>20<br>40<br>60<br>80<br>Test Accuracy|~~300~~<br>~~500~~<br>~~70~~<br>Number of Iterati|~~0~~<br>~~900~~<br>ons|



**(h) CIFAR-10: Scaling attack with norm**
**bound validation predicate**



|80<br>60<br>40<br>20<br>100<br>Num|Col2|
|---|---|
|~~100~~<br>Num<br>20<br>40<br>60<br>80<br>|~~200~~<br>~~300~~<br>~~400~~<br>~~500~~<br>er of Iterations|


**(c) FMNIST: Min-Sum attack with co-**
**sine similarity validation predicate.**

|80<br>60<br>40<br>20<br>100 300<br>Num|Col2|
|---|---|
|~~100~~<br>~~300~~<br>Num<br>20<br>40<br>60<br>80<br>|~~500~~<br>~~700~~<br>~~900~~<br>er of Iterations|



**(g) CIFAR-10: Min-Max attack with**
**Zeno++ validation predicate.**



**(a) MNIST: Scaling attack with norm**
**bound validation predicate.**


**(e) EMNIST: Scaling attack with cosine**
**similarity validation predicate.**



**(b) FMNIST: Scaling attack with norm**
**bound validation predicate.**


**(f) EMNIST: Sign flip attack with norm**
**ball validation predicate.**



**(i) CIFAR-10: Sign flip attack with**
**norm ball validation predicate.**


**Figure 9: Accuracy analysis of EIFFeL continued. Test accuracy is shown as a function of the FL iteration for different datasets and attacks.**



**Scaling EIFFeL.** Our experimental results in Sec. 7 show that EIFFeL has reasonable performance for clients sizes up to 250. One way
of scaling EIFFeL for larger client sizes can be by dividing the clients
into smaller subsets of size âˆ¼ 250 and then running EIFFeL for each
of these subsets [16].


**Towards poly-logarithmic complexity.** Currently, dominant term
in the complexity is _ğ‘‚_ ( _ğ‘šğ‘›ğ‘‘_ ) which results in a _ğ‘‚_ ( _ğ‘›_ [2] ) dependence
on _ğ‘›_ (since we consider _ğ‘š_ is a fraction of _ğ‘›_ ). This can be reduced
to _ğ‘‚_ ( _ğ‘›_ log [2] _ğ‘›ğ‘‘_ ) by using the techniques from [ 9 ]. Specifically, instead of having each client verify the proofs of all others (complete
graph for the verification) we can follow the exact construction
of the _ğ‘˜_ -regular graph _ğº_ from [ 9 ] such that _ğ‘˜_ = _ğ‘‚_ (log _ğ‘›_ ) and only
neighbors in _ğº_ act as verifiers for each other. The exact steps are
as follows:


(1) Each client _ğ¶_ _ğ‘–_ generates _ğ‘›_ shares. It sends the corresponding
shares to its _ğ‘˜_ -neighbors (according to graph G from [9]) and
the verification can be done on them as described currently
in EIFFeL. Note that these shares follow a _ğ‘¡_ -out-of- _ğ‘›_ scheme

where _ğ‘¡_ _< ğ‘˜_ .


(2) _ğ¶_ _ğ‘–_ encrypts the shares for the non-neighbors using a threshold
(denoted by _ğ‘¡_ _ğ‘’ğ‘›ğ‘_ ) fully homomorphic encryption scheme such
as BGV [ 22 ] (the threshold variant can be obtained using work
such as [ 20, 42 ]). Note that this threshold, _ğ‘¡_ _ğ‘’ğ‘›ğ‘_ _> ğ‘š_ is different



from that of the secret shares. This encryption is necessary for
ensuring data privacy since for the threshold of the shares we
could have _ğ‘¡_ _< ğ‘š_ .


(3) For the aggregation step, first the clients check the validity of
the shares of its non-neighbors (this can be done via homomorphic multiplications as shown by Feldman [ 35 ]). Next, only the
shares corresponding to the clients that (i) pass the first step
of input verification, and (ii) have valid shares, are aggregated.
Note that the shares corresponding to neighbors (for verification) can be encrypted using the public key of the encryption
scheme for this step.


(4) Each client now has the ciphertext of its share of the aggregate
(corresponding to ( _ğ‘–,ğ‘ˆ_ _ğ‘–_ ) where _ğ‘ˆ_ _ğ‘–_ = [ï¿½] _ğ¶_ _ğ‘—_ âˆˆ _ğ¶_ \ _ğ¶_ âˆ— _[ğ‘¢]_ _ğ‘—ğ‘–_ [in the cur-]
rent EIFFeL protocol) which is sent to the server. The server
performs the reconstruction directly on these ciphertexts (using
their homomorphic property) and obtains the ciphertext of the
final aggregate. This can then be decrypted with the help of the
clients to obtain the final aggregate in the clear.


